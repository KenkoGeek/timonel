<?xml version="1.0" encoding="UTF-8"?>
<repository>
<repository_structure>
  <file name=".releaserc.json"/>
  <directory name=".husky">
    <directory name="_">
      <file name="pre-rebase"/>
      <file name="pre-applypatch"/>
      <file name="husky.sh"/>
      <file name="pre-auto-gc"/>
      <file name="pre-merge-commit"/>
      <file name="post-commit"/>
      <file name="applypatch-msg"/>
      <file name="prepare-commit-msg"/>
      <file name="h"/>
      <file name="post-checkout"/>
      <file name="post-applypatch"/>
      <file name=".gitignore"/>
      <file name="post-rewrite"/>
      <file name="commit-msg"/>
      <file name="pre-push"/>
      <file name="post-merge"/>
      <file name="pre-commit"/>
    </directory>
    <file name="commit-msg"/>
    <file name="pre-commit"/>
  </directory>
  <file name=".markdownlintignore"/>
  <file name="LICENSE"/>
  <file name="CHANGELOG.md"/>
  <file name="tsconfig.cli.json"/>
  <file name=".prettierignore"/>
  <file name=".editorconfig"/>
  <file name=".prettierrc.json"/>
  <file name=".gitignore"/>
  <file name="package.json"/>
  <directory name="examples">
    <directory name="wordpress">
      <file name="README.md"/>
      <file name="package.json"/>
    </directory>
    <directory name="aws-game-2048">
      <file name="README.md"/>
      <file name="chart.ts"/>
      <file name="package.json"/>
    </directory>
    <directory name="wordpress-umbrella">
      <file name="chart.ts"/>
      <file name="package.json"/>
    </directory>
  </directory>
  <directory name=".github">
    <directory name="workflows">
      <file name="release.yml"/>
      <file name="publish.yml"/>
      <file name="codeql.yml"/>
      <file name="ci.yml"/>
    </directory>
    <file name="pull_request_template.md"/>
    <directory name="ISSUE_TEMPLATE">
      <file name="feature_request.md"/>
      <file name="bug_report.md"/>
    </directory>
    <file name="dependabot.yml"/>
  </directory>
  <file name=".commitlintrc.cjs"/>
  <directory name=".amazonq">
    <directory name="agents">
      <file name="default.json"/>
    </directory>
    <file name="Instrucciones.md"/>
    <directory name="scripts">
      <file name="map-pr-comments.sh"/>
    </directory>
  </directory>
  <file name="tsconfig.json"/>
  <file name=".commitlintrc.json"/>
  <directory name=".workflowforge">
    <file name="requirements.txt"/>
    <file name="README.md"/>
    <directory name=".venv-3.13">
      <directory name="bin">
        <file name="Activate.ps1"/>
        <file name="pip3.13"/>
        <file name="pip3"/>
        <file name="activate.fish"/>
        <file name="pip"/>
        <file name="activate"/>
        <file name="normalizer"/>
        <file name="activate.csh"/>
      </directory>
      <file name="pyvenv.cfg"/>
      <file name=".gitignore"/>
    </directory>
  </directory>
  <file name="eslint.config.js"/>
  <file name=".markdownlint.json"/>
  <file name="SECURITY.md"/>
  <directory name="src">
    <file name="cli.ts"/>
    <file name="index.ts"/>
  </directory>
</repository_structure>
<repository_files>
  <file>
    
  
    <path>.releaserc.json</path>
    
  
    <content>{
  &quot;branches&quot;: [&quot;main&quot;],
  &quot;plugins&quot;: [
    &quot;@semantic-release/commit-analyzer&quot;,
    &quot;@semantic-release/release-notes-generator&quot;,
    &quot;@semantic-release/changelog&quot;,
    &quot;@semantic-release/npm&quot;,
    &quot;@semantic-release/github&quot;,
    [
      &quot;@semantic-release/git&quot;,
      {
        &quot;assets&quot;: [&quot;package.json&quot;, &quot;CHANGELOG.md&quot;, &quot;examples/*/package.json&quot;],
        &quot;message&quot;: &quot;chore(release): ${nextRelease.version} [skip ci]\n\n${nextRelease.notes}&quot;
      }
    ]
  ]
}</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/pre-rebase</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/pre-applypatch</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/husky.sh</path>
    
  
    <content>echo &quot;husky - DEPRECATED

Please remove the following two lines from $0:

#!/usr/bin/env sh
. \&quot;\$(dirname -- \&quot;\$0\&quot;)/_/husky.sh\&quot;

They WILL FAIL in v10.0.0
&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/pre-auto-gc</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/pre-merge-commit</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/post-commit</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/applypatch-msg</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/prepare-commit-msg</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/h</path>
    
  
    <content>#!/usr/bin/env sh
[ &quot;$HUSKY&quot; = &quot;2&quot; ] &amp;&amp; set -x
n=$(basename &quot;$0&quot;)
s=$(dirname &quot;$(dirname &quot;$0&quot;)&quot;)/$n

[ ! -f &quot;$s&quot; ] &amp;&amp; exit 0

if [ -f &quot;$HOME/.huskyrc&quot; ]; then
	echo &quot;husky - '~/.huskyrc' is DEPRECATED, please move your code to ~/.config/husky/init.sh&quot;
fi
i=&quot;${XDG_CONFIG_HOME:-$HOME/.config}/husky/init.sh&quot;
[ -f &quot;$i&quot; ] &amp;&amp; . &quot;$i&quot;

[ &quot;${HUSKY-}&quot; = &quot;0&quot; ] &amp;&amp; exit 0

export PATH=&quot;node_modules/.bin:$PATH&quot;
sh -e &quot;$s&quot; &quot;$@&quot;
c=$?

[ $c != 0 ] &amp;&amp; echo &quot;husky - $n script failed (code $c)&quot;
[ $c = 127 ] &amp;&amp; echo &quot;husky - command not found in PATH=$PATH&quot;
exit $c</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/post-checkout</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/post-applypatch</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/.gitignore</path>
    
  
    <content>*</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/post-rewrite</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/commit-msg</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/pre-push</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/post-merge</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/_/pre-commit</path>
    
  
    <content>#!/usr/bin/env sh
. &quot;$(dirname &quot;$0&quot;)/h&quot;</content>
    

  </file>
  <file>
    
  
    <path>.husky/commit-msg</path>
    
  
    <content>#!/usr/bin/env sh

# Validate conventional commits with mandatory scopes
echo &quot;üîç Validating commit message format...&quot;
pnpm exec commitlint --edit &quot;$1&quot; || {
  echo &quot;‚ùå Commit message validation failed!&quot;
  echo &quot;&quot;
  echo &quot;üìù Required format: type(scope): description&quot;
  echo &quot;&quot;
  echo &quot;üìã Valid types: feat, fix, docs, style, refactor, perf, test, chore, ci, build, revert&quot;
  echo &quot;üìã Valid scopes: core, cli, helm, aws, network, umbrella, examples, docs, ci, deps, release&quot;
  echo &quot;&quot;
  echo &quot;‚úÖ Examples:&quot;
  echo &quot;   feat(network): add NetworkPolicy helpers&quot;
  echo &quot;   fix(core): resolve TypeScript strict type errors&quot;
  echo &quot;   docs(examples): update WordPress example&quot;
  echo &quot;   chore(release): bump version to 0.5.0&quot;
  echo &quot;&quot;
  exit 1
}</content>
    

  </file>
  <file>
    
  
    <path>.husky/pre-commit</path>
    
  
    <content>#!/usr/bin/env sh

echo &quot;Running lint-staged...&quot;
pnpm exec lint-staged || npx --no-install lint-staged || exit 1

echo &quot;Running markdownlint (fix) for Markdown...&quot;
pnpm exec markdownlint --fix &quot;**/*.md&quot; || npx --no-install markdownlint --fix &quot;**/*.md&quot; || exit 1</content>
    

  </file>
  <file>
    
  
    <path>.markdownlintignore</path>
    
  
    <content>CHANGELOG.md
node_modules/
**/node_modules/
dist/
coverage/
.git/
CHANGELOG.md
examples/node_modules/
amazonq/</content>
    

  </file>
  <file>
    
  
    <path>LICENSE</path>
    
  
    <content>MIT License

Copyright (c) 2025 Franklin Garc√≠a

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &quot;Software&quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</content>
    

  </file>
  <file>
    
  
    <path>CHANGELOG.md</path>
    
  
    <content># Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

## [0.4.0] - 2025-09-06

### Added (0.4.0)

- **Custom Manifest Naming**: Complete implementation for customizable Kubernetes
  manifest file names
  - `manifestName` option in RutterProps to specify custom base names for manifest
    files
  - `singleManifestFile` option to combine all resources into a single manifest
    file
  - Enhanced file organization with descriptive names instead of generic numbered
    files
  - Support for both single file mode (`application.yaml`) and separate files mode
    (`0000-my-app-deployment-web.yaml`)
  - Backward compatibility maintained - default behavior unchanged when options not
    specified

### Enhanced (0.4.0)

- **HelmChartWriter**: Added `singleFile` property to SynthAsset interface for
  improved file handling
- **Documentation**: Comprehensive Custom Manifest Naming section added to README
  with examples
- **Examples**: All examples updated with custom manifest naming demonstrations
  - **AWS 2048 Game**: Enhanced with production-ready AWS features
    - AWS ALB Ingress with health checks and SSL support
    - HorizontalPodAutoscaler (HPA) for CPU-based auto-scaling
    - PodDisruptionBudget (PDB) for high availability during updates
    - Custom manifest naming with `manifestName: 'game-2048'`
    - Multi-environment configuration (dev/staging/prod)
  - **WordPress**: Updated to showcase `manifestName: 'wordpress-app'` and `singleManifestFile: true`
    - Comprehensive AWS integration examples (EBS, EFS, IRSA, Secrets Manager)
    - Auto-scaling with HPA and VPA configurations
    - Production-ready deployment patterns
  - **WordPress Umbrella**: Subcharts updated with custom manifest naming
    - MySQL subchart: `manifestName: 'mysql-database'`, `singleManifestFile: true`
    - WordPress subchart: `manifestName: 'wordpress-app'`, `singleManifestFile: false`
- **Example Documentation**: All example READMEs enhanced with custom manifest naming references
  and comprehensive deployment instructions
- **Auto-scaling Features**: Properly documented existing production-ready capabilities
  - HorizontalPodAutoscaler (HPA) with CPU/memory metrics and custom behavior policies
  - VerticalPodAutoscaler (VPA) with resource policies and update modes
  - PodDisruptionBudget (PDB) for high availability during updates
- **AWS Multi-Cloud Support**: Comprehensive documentation of EKS integration features
  - AWS IRSA ServiceAccount for secure IAM role assumption with regional STS endpoints
  - AWS EBS StorageClass with GP3, IO1, IO2 support, encryption, and IOPS configuration
  - AWS EFS StorageClass for shared storage across pods with access points
  - AWS ALB Ingress with health checks, SSL certificates, and advanced routing
  - AWS Secrets Manager and Parameter Store integration via SecretProviderClass
  - Multi-cloud ServiceAccount with workload identity (AWS IRSA, Azure, GCP)

## [0.3.0] - 2025-09-02

### Added (0.3.0)

- **Umbrella Charts Support**: Complete implementation for managing multiple subcharts
  - `UmbrellaRutter` class for coordinating multiple Rutter instances
  - `createUmbrella()` helper function for easy umbrella chart creation
  - CLI commands: `tl umbrella init`, `tl umbrella add`, `tl umbrella synth`
  - Automatic Chart.yaml generation with dependencies
  - Support for environment-specific values in umbrella charts
  - Example templates for umbrella and subchart scaffolding
- **WordPress Umbrella Example**: Complete example separating MySQL and WordPress into subcharts
  - MySQL subchart with persistent storage and secrets
  - WordPress subchart with database connectivity
  - Multi-environment configuration (dev/prod)
  - Comprehensive documentation and deployment guide

### Changed (0.3.0)

- Updated CLI usage to include umbrella chart commands
- Enhanced example generation with subchart support

### Removed

- **BREAKING**: Removed unused `cdk8s-plus-28` dependency
  - Project uses `ApiObject` directly for better control
  - No impact on functionality, only dependency cleanup

## [0.2.1] - 2025-09-02

### Fixed

- Updated examples package.json versions to 0.2.0 for consistency
- Fixed examples imports to use relative paths instead of 'timonel' package
- Updated dependencies to resolve brace-expansion security vulnerability
- Examples now work correctly with CLI after v0.2.0 breaking changes

### Security

- Updated dependencies to latest versions
- Resolved brace-expansion vulnerability in transitive dependencies

## [0.2.0] - 2025-09-02

### BREAKING CHANGES

- **API Change**: Renamed `ChartFactory` class to `Rutter` (maritime pilot concept)
- **Import Change**: `import { ChartFactory }` ‚Üí `import { Rutter }`
- **Constructor Change**: `new ChartFactory()` ‚Üí `new Rutter()`
- **File Renamed**: `ChartFactory.ts` ‚Üí `Rutter.ts`

### Migration Guide

```typescript
// Before v0.2.0
import { ChartFactory } from 'timonel';
const factory = new ChartFactory({ meta: { name: 'my-app' } });

// After v0.2.0
import { Rutter } from 'timonel';
const rutter = new Rutter({ meta: { name: 'my-app' } });
```

### Implementation

- Updated all examples and documentation to use `Rutter` terminology
- Updated CLI template generation and --set flag integration
- Updated package.json description: 'chart factory' ‚Üí 'chart generator'
- Eliminated all factory references from codebase
- Enhanced maritime theme consistency (Timonel + Rutter)

## [0.1.7] - 2025-09-01

### Breaking Changes

- **BREAKING**: Renamed `ChartFactory` class to `Rutter` (maritime pilot concept)
- Updated all examples and documentation to use `Rutter` instead of `ChartFactory`
- Renamed `ChartFactory.ts` to `Rutter.ts` for consistency
- Updated API: `new Rutter()` instead of `new ChartFactory()`

## [0.1.6] - 2025-09-01

### Structure

- Renamed `example/` directory to `examples/` for better clarity
- Updated linting ignore patterns to use `examples/**`
- Added Examples section to README documenting available examples

## [0.1.5] - 2025-08-31

### Linting

- Excluded example directories from main lint script to resolve CI errors
- Ensure both lint and security:lint scripts ignore example imports

## [0.1.4] - 2025-08-31

### Updated

- Updated TypeScript configuration to use Node16 module and moduleResolution
- Resolved deprecated moduleResolution warning for TypeScript 7.0 compatibility
- Modernized module resolution while maintaining CommonJS compatibility

### CI

- Excluded example directories from security linting to resolve CI import errors

## [0.1.3] - 2025-08-31

### Bug Fixes 0.1.3

- Fixed Helm chart generation issues with numeric values in YAML
- Corrected environment variable handling for complex objects
- Fixed PersistentVolumeClaim volume references
- Resolved Service port type casting issues
- Updated examples to use literal numeric values instead of numberRef for critical fields

### Changed

- Simplified WordPress example to use string environment variables instead of valueFrom objects
- Updated AWS 2048 example to use literal ports and replicas
- Improved README documentation with corrected deployment examples
- Removed redundant DEPLOYMENT.md file from aws-game-2048 example

### Documentation

- Enhanced main README with better examples and troubleshooting
- Updated example READMEs with working deployment commands
- Added notes about numeric value handling in Helm templates

## [0.1.2] - 2025-08-30

### Added

- Enhanced `validate` command to generate chart and run `helm lint` for proper validation
- Helm installation detection with clear installation instructions
- Automatic cleanup of temporary validation directories

### Bug Fixes 0.1.2

- Fixed example chart to use valid Helm template syntax for annotations
- Improved error messages with installation links for missing Helm binary

## [0.1.1] - 2025-08-30

### Resolved

- Fixed TypeScript module resolution error in CLI when validating charts
- Added explicit ts-node configuration to prevent module resolution error
- Added `exports` field to package.json to support subpath imports like `timonel/lib/helm`

## [0.1.0] - 2025-08-30

### Initial

- Initial release of Timonel - TypeScript library for programmatic Helm chart generation
- ChartFactory class with support for Deployments, Services, Ingress, ConfigMaps, Secrets
- PersistentVolume and PersistentVolumeClaim support with multi-cloud optimization
- ServiceAccount with workload identity support (AWS IRSA, Azure, GCP)
- Multi-environment values support (dev, staging, prod)
- CLI tool (`tl`) with commands: init, synth, validate, diff, deploy, package
- CI/CD integration with --dry-run, --silent, --env flags
- Dynamic value overrides with --set flag and dot notation support
- Helm templating helpers with programmatic \_helpers.tpl generation
- Type-safe API with cdk8s constructs and Helm placeholder preservation
- Comprehensive AWS 2048 game example with EKS deployment
- Security-focused development with ESLint security plugin and audit pipeline
- GitHub Actions workflows for CI/CD with provenance-enabled publishing

### Security Features

- ESLint security plugin with 12+ vulnerability detection rules
- Automated dependency scanning via Dependabot
- CodeQL analysis for code security
- Security audit in CI/CD pipeline
- Provenance-enabled npm publishing

[Unreleased]: https://github.com/KenkoGeek/timonel/compare/v0.4.0...HEAD
[0.4.0]: https://github.com/KenkoGeek/timonel/releases/tag/v0.4.0
[0.3.0]: https://github.com/KenkoGeek/timonel/releases/tag/v0.3.0
[0.2.1]: https://github.com/KenkoGeek/timonel/releases/tag/v0.2.1
[0.2.0]: https://github.com/KenkoGeek/timonel/releases/tag/v0.2.0
[0.1.7]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.7
[0.1.6]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.6
[0.1.5]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.5
[0.1.4]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.4
[0.1.3]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.3
[0.1.2]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.2
[0.1.1]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.1
[0.1.0]: https://github.com/KenkoGeek/timonel/releases/tag/v0.1.0</content>
    

  </file>
  <file>
    
  
    <path>tsconfig.cli.json</path>
    
  
    <content>{
  &quot;extends&quot;: &quot;./tsconfig.json&quot;,
  &quot;compilerOptions&quot;: {
    &quot;module&quot;: &quot;CommonJS&quot;,
    &quot;moduleResolution&quot;: &quot;node&quot;
  },
  &quot;ts-node&quot;: {
    &quot;transpileOnly&quot;: true,
    &quot;compilerOptions&quot;: {
      &quot;module&quot;: &quot;CommonJS&quot;,
      &quot;moduleResolution&quot;: &quot;node&quot;
    }
  }
}</content>
    

  </file>
  <file>
    
  
    <path>.prettierignore</path>
    
  
    <content>dist/
node_modules/
*.log
pnpm-lock.yaml</content>
    

  </file>
  <file>
    
  
    <path>.editorconfig</path>
    
  
    <content>root = true

[*]
charset = utf-8
end_of_line = lf
indent_style = space
indent_size = 2
insert_final_newline = true
trim_trailing_whitespace = true
max_line_length = 100

[*.{js,ts,tsx,jsx}]
indent_style = space
indent_size = 2
max_line_length = 100

[*.{json,yml,yaml}]
indent_style = space
indent_size = 2

[*.md]
trim_trailing_whitespace = false
max_line_length = off

[{package.json,*.lock}]
indent_style = space
indent_size = 2

[*.{sh,bash}]
indent_style = space
indent_size = 2
end_of_line = lf</content>
    

  </file>
  <file>
    
  
    <path>.prettierrc.json</path>
    
  
    <content>{
  &quot;printWidth&quot;: 100,
  &quot;singleQuote&quot;: true,
  &quot;trailingComma&quot;: &quot;all&quot;,
  &quot;semi&quot;: true,
  &quot;arrowParens&quot;: &quot;always&quot;,
  &quot;tabWidth&quot;: 2,
  &quot;useTabs&quot;: false,
  &quot;quoteProps&quot;: &quot;as-needed&quot;,
  &quot;bracketSpacing&quot;: true,
  &quot;bracketSameLine&quot;: false,
  &quot;endOfLine&quot;: &quot;lf&quot;
}</content>
    

  </file>
  <file>
    
  
    <path>.gitignore</path>
    
  
    <content>node_modules/
dist/
.DS_Store
npm-debug.log*
pnpm-debug.log*
.pnpm-store/
*.tgz
.npmrc
.env
.env.*
.vscode/
.amazonq/
.idea/
.node_repl_history
.nyc_output/
.coverage
coverage/
charts/**/dist/
__pycache__/
.pytest_cache/
.venv*
.workflowforge/.venv/
.python-version
imports/
cdk8s.out/
DS_Store</content>
    

  </file>
  <file>
    
  
    <path>package.json</path>
    
  
    <content>{
  &quot;name&quot;: &quot;timonel&quot;,
  &quot;type&quot;: &quot;module&quot;,
  &quot;version&quot;: &quot;0.4.0&quot;,
  &quot;description&quot;: &quot;Timonel: programmatic Helm chart generator using cdk8s (TypeScript)&quot;,
  &quot;bin&quot;: {
    &quot;timonel&quot;: &quot;dist/cli.js&quot;,
    &quot;tl&quot;: &quot;dist/cli.js&quot;
  },
  &quot;main&quot;: &quot;dist/index.js&quot;,
  &quot;types&quot;: &quot;dist/index.d.ts&quot;,
  &quot;exports&quot;: {
    &quot;.&quot;: {
      &quot;types&quot;: &quot;./dist/index.d.ts&quot;,
      &quot;default&quot;: &quot;./dist/index.js&quot;
    },
    &quot;./lib/helm&quot;: {
      &quot;types&quot;: &quot;./dist/lib/helm.d.ts&quot;,
      &quot;default&quot;: &quot;./dist/lib/helm.js&quot;
    }
  },
  &quot;scripts&quot;: {
    &quot;build&quot;: &quot;tsc -p tsconfig.json&quot;,
    &quot;clean&quot;: &quot;rm -rf dist&quot;,
    &quot;dev&quot;: &quot;tsc -w -p tsconfig.json&quot;,
    &quot;prepare&quot;: &quot;husky&quot;,
    &quot;prepack&quot;: &quot;pnpm build&quot;,
    &quot;typecheck&quot;: &quot;tsc -p tsconfig.json --noEmit&quot;,
    &quot;lint&quot;: &quot;eslint .&quot;,
    &quot;lint:fix&quot;: &quot;eslint . --fix&quot;,
    &quot;format&quot;: &quot;prettier --write .&quot;,
    &quot;format:check&quot;: &quot;prettier --check .&quot;,
    &quot;security:lint&quot;: &quot;eslint . --ext .ts,.tsx --ignore-pattern 'examples/**'&quot;,
    &quot;security:audit&quot;: &quot;pnpm audit --audit-level=moderate&quot;,
    &quot;security:check&quot;: &quot;pnpm run security:lint &amp;&amp; pnpm run security:audit&quot;,
    &quot;deps:check&quot;: &quot;pnpm outdated&quot;,
    &quot;deps:update&quot;: &quot;pnpm update --latest&quot;,
    &quot;md:lint&quot;: &quot;markdownlint \&quot;**/*.md\&quot;&quot;,
    &quot;md:fix&quot;: &quot;markdownlint --fix \&quot;**/*.md\&quot;&quot;,
    &quot;test&quot;: &quot;echo \&quot;No tests specified\&quot; &amp;&amp; exit 0&quot;,
    &quot;ci:check&quot;: &quot;pnpm typecheck &amp;&amp; pnpm lint &amp;&amp; pnpm format:check &amp;&amp; pnpm build&quot;,
    &quot;release&quot;: &quot;semantic-release&quot;,
    &quot;release:dry&quot;: &quot;semantic-release --dry-run&quot;,
    &quot;version:patch&quot;: &quot;npm version patch &amp;&amp; echo 'Remember to update CHANGELOG.md'&quot;,
    &quot;version:minor&quot;: &quot;npm version minor &amp;&amp; echo 'Remember to update CHANGELOG.md'&quot;,
    &quot;version:major&quot;: &quot;npm version major &amp;&amp; echo 'Remember to update CHANGELOG.md'&quot;
  },
  &quot;keywords&quot;: [
    &quot;helm&quot;,
    &quot;charts&quot;,
    &quot;cdk8s&quot;,
    &quot;kubernetes&quot;,
    &quot;iac&quot;
  ],
  &quot;author&quot;: &quot;Franklin Garc√≠a &lt;KenkoGeek&gt;&quot;,
  &quot;license&quot;: &quot;MIT&quot;,
  &quot;engines&quot;: {
    &quot;node&quot;: &quot;&gt;=20&quot;,
    &quot;pnpm&quot;: &quot;&gt;=9.0.0&quot;
  },
  &quot;repository&quot;: {
    &quot;type&quot;: &quot;git&quot;,
    &quot;url&quot;: &quot;git+https://github.com/KenkoGeek/timonel.git&quot;
  },
  &quot;bugs&quot;: {
    &quot;url&quot;: &quot;https://github.com/KenkoGeek/timonel/issues&quot;
  },
  &quot;homepage&quot;: &quot;https://github.com/KenkoGeek/timonel#readme&quot;,
  &quot;lint-staged&quot;: {
    &quot;**/*.{ts,tsx}&quot;: [
      &quot;eslint --fix&quot;,
      &quot;prettier --write&quot;
    ],
    &quot;**/*.{js,cjs,json,yml,yaml}&quot;: [
      &quot;prettier --write&quot;
    ],
    &quot;**/*.md&quot;: [
      &quot;markdownlint --fix&quot;
    ]
  },
  &quot;dependencies&quot;: {
    &quot;cdk8s&quot;: &quot;^2.70.11&quot;,
    &quot;ts-node&quot;: &quot;^10.9.2&quot;,
    &quot;yaml&quot;: &quot;^2.8.1&quot;
  },
  &quot;devDependencies&quot;: {
    &quot;@commitlint/cli&quot;: &quot;^19.8.1&quot;,
    &quot;@commitlint/config-conventional&quot;: &quot;^19.8.1&quot;,
    &quot;@eslint/js&quot;: &quot;^9.35.0&quot;,
    &quot;@semantic-release/changelog&quot;: &quot;^6.0.3&quot;,
    &quot;@semantic-release/git&quot;: &quot;^10.0.1&quot;,
    &quot;@types/node&quot;: &quot;^24.3.0&quot;,
    &quot;@typescript-eslint/eslint-plugin&quot;: &quot;^8.42.0&quot;,
    &quot;@typescript-eslint/parser&quot;: &quot;^8.42.0&quot;,
    &quot;conventional-changelog-cli&quot;: &quot;^5.0.0&quot;,
    &quot;eslint&quot;: &quot;^9.35.0&quot;,
    &quot;eslint-config-prettier&quot;: &quot;^10.1.8&quot;,
    &quot;eslint-import-resolver-typescript&quot;: &quot;^4.4.4&quot;,
    &quot;eslint-plugin-import&quot;: &quot;^2.32.0&quot;,
    &quot;eslint-plugin-security&quot;: &quot;^3.0.1&quot;,
    &quot;eslint-plugin-sonarjs&quot;: &quot;^3.0.5&quot;,
    &quot;eslint-plugin-unused-imports&quot;: &quot;^4.2.0&quot;,
    &quot;husky&quot;: &quot;^9.1.7&quot;,
    &quot;lint-staged&quot;: &quot;^16.1.6&quot;,
    &quot;markdownlint&quot;: &quot;^0.38.0&quot;,
    &quot;markdownlint-cli&quot;: &quot;^0.45.0&quot;,
    &quot;prettier&quot;: &quot;^3.6.2&quot;,
    &quot;semantic-release&quot;: &quot;^24.2.7&quot;,
    &quot;typescript&quot;: &quot;^5.9.2&quot;
  },
  &quot;files&quot;: [
    &quot;dist&quot;,
    &quot;README.md&quot;,
    &quot;CHANGELOG.md&quot;,
    &quot;SECURITY.md&quot;,
    &quot;LICENSE&quot;
  ],
  &quot;publishConfig&quot;: {
    &quot;access&quot;: &quot;public&quot;,
    &quot;provenance&quot;: true
  },
  &quot;packageManager&quot;: &quot;pnpm@10.15.0+sha512.486ebc259d3e999a4e8691ce03b5cac4a71cbeca39372a9b762cb500cfdf0873e2cb16abe3d951b1ee2cf012503f027b98b6584e4df22524e0c7450d9ec7aa7b&quot;
}</content>
    

  </file>
  <file>
    
  
    <path>examples/wordpress/README.md</path>
    
  
    <content># WordPress with MySQL Helm Chart

This example demonstrates deploying WordPress with MySQL database using Timonel.

## Features

- WordPress 6.4.0 with Apache
- MySQL 8.0 database
- Persistent storage for MySQL
- Secrets management for database credentials
- Multi-environment configuration (dev/staging/prod)
- Resource requests and limits
- LoadBalancer service
- **Custom Manifest Naming**: Single file organization with `manifestName: 'wordpress-app'`

## Quick Start

1. **Generate the chart:**

   ```bash
   # From project root
   pnpm tl synth examples/wordpress wordpress-chart
   ```

   This generates a single manifest file `templates/wordpress-app.yaml` containing all
   resources,
   thanks to the custom manifest naming configuration (`manifestName: 'wordpress-app'`,
   `singleManifestFile: true`).

2. **Deploy to Kubernetes:**

   ```bash
   # Production deployment with LoadBalancer
   helm install wordpress wordpress-chart -f wordpress-chart/values-prod.yaml

   # Development deployment
   helm install wordpress wordpress-chart -f wordpress-chart/values-dev.yaml

   # Local/Kind deployment with NodePort
   helm install wordpress wordpress-chart \
     -f wordpress-chart/values-dev.yaml \
     --set service.type=NodePort
   ```

## Configuration

### WordPress Settings

- `wordpress.image`: WordPress Docker image
- `wordpress.replicas`: Number of WordPress pods
- `wordpress.resources`: CPU and memory requests

### MySQL Settings

- `mysql.image`: MySQL Docker image
- `mysql.rootPassword`: MySQL root password
- `mysql.database`: WordPress database name
- `mysql.user`: WordPress database user
- `mysql.password`: WordPress database password
- `mysql.storage`: Persistent volume size

### Service Settings

- `service.type`: Kubernetes service type (LoadBalancer, ClusterIP, NodePort)
- `service.port`: Service port

## Environment Configurations

- **dev**: 1 WordPress replica, 5Gi MySQL storage
- **staging**: 2 WordPress replicas, 8Gi MySQL storage
- **prod**: 3 WordPress replicas, 20Gi MySQL storage

## Security Notes

‚ö†Ô∏è **Important**: Change default passwords in production!

Update `mysql.rootPassword` and `mysql.password` values before deploying to production.

## Accessing WordPress

After deployment:

**For LoadBalancer service:**

```bash
kubectl get services wordpress-service
# Navigate to EXTERNAL-IP in browser
```

**For NodePort or local access:**

```bash
kubectl port-forward svc/wordpress-service 8080:80
open http://localhost:8080
```

**Check deployment status:**

```bash
kubectl get pods
kubectl get pvc
```</content>
    

  </file>
  <file>
    
  
    <path>examples/wordpress/package.json</path>
    
  
    <content>{
  &quot;name&quot;: &quot;wordpress-example&quot;,
  &quot;version&quot;: &quot;0.4.0&quot;,
  &quot;description&quot;: &quot;WordPress with MySQL Helm chart example using Timonel&quot;,
  &quot;private&quot;: true,
  &quot;scripts&quot;: {
    &quot;build&quot;: &quot;tl synth . ./dist&quot;,
    &quot;package&quot;: &quot;tl package ./dist ./&quot;
  },
  &quot;keywords&quot;: [
    &quot;timonel&quot;,
    &quot;helm&quot;,
    &quot;kubernetes&quot;,
    &quot;wordpress&quot;,
    &quot;mysql&quot;
  ],
  &quot;dependencies&quot;: {
    &quot;timonel&quot;: &quot;^0.4.0&quot;
  }
}</content>
    

  </file>
  <file>
    
  
    <path>examples/aws-game-2048/README.md</path>
    
  
    <content># AWS 2048 Game Example

This example demonstrates how to use Timonel to create a Helm chart for deploying the AWS 2048
game on Amazon EKS with Application Load Balancer (ALB) ingress.

## Overview

The example creates a production-ready Kubernetes deployment including:

- **Deployment**: 5 replicas of the 2048 game container with resource requests
- **Service**: ClusterIP service to expose the deployment
- **AWS ALB Ingress**: Internet-facing Application Load Balancer with health checks
- **HorizontalPodAutoscaler (HPA)**: CPU-based auto-scaling (70% utilization)
- **PodDisruptionBudget (PDB)**: High availability during updates and maintenance
- **Custom Manifest Naming**: Descriptive file names (`game-2048-deployment-app-2048.yaml`)

## Prerequisites

- Amazon EKS cluster with AWS Load Balancer Controller installed
- `kubectl` configured to access your cluster
- Helm 3.x installed
- Proper subnet tags for EKS Auto Mode (if using)

## Quick Start

1. **Generate the Helm chart**:

```bash
# From project root
pnpm tl synth examples/aws-game-2048 dist/game-2048
```

1. **Deploy to your EKS cluster**:

```bash
# Deploy to production
helm install game-2048 dist/game-2048 -f dist/game-2048/values-prod.yaml

# Deploy to development
helm install game-2048 dist/game-2048 -f dist/game-2048/values-dev.yaml

# Deploy to Kind/local cluster (without ALB)
helm install game-2048 dist/game-2048 \
  -f dist/game-2048/values-dev.yaml \
  --set ingress.enabled=false \
  --set service.type=NodePort
```

1. **Access the game**:

For EKS with ALB:

```bash
kubectl get ingress ingress-2048
# Open the ALB endpoint URL in browser
```

For local/Kind:

```bash
kubectl port-forward svc/service-2048 8080:80
open http://localhost:8080
```

## Configuration

### Default Values

The chart includes sensible defaults:

- **Replicas**: 5 (configurable per environment)
- **Image**: `public.ecr.aws/l6m2t8p7/docker-2048:latest`
- **Resources**: 0.5 CPU request per pod
- **ALB**: Internet-facing with IP target type

### Environment Values

- **dev**: 2 replicas
- **staging**: 3 replicas
- **prod**: 5 replicas

### Key Features

- **Multi-environment support**: Different replica counts and scaling policies for dev/staging/prod
- **AWS ALB Integration**: Production-ready Application Load Balancer with health checks
- **Auto-scaling**: HPA with intelligent scaling policies and stabilization windows
- **High Availability**: PDB ensures minimum pod availability during disruptions
- **Resource management**: CPU and memory requests for proper scheduling
- **Custom Manifest Naming**: Descriptive file organization with `manifestName: 'game-2048'`
- **Kubernetes best practices**: Proper labels, selectors, and AWS-specific annotations

## Architecture

### Components

1. **Rutter**: Main class with custom manifest naming (`manifestName: 'game-2048'`)
2. **Deployment**: Manages the 2048 game pods with resource requests and proper labels
3. **Service**: Provides stable networking for the pods
4. **AWS ALB Ingress**: Production-ready load balancer with health checks and SSL support
5. **HorizontalPodAutoscaler**: CPU-based auto-scaling with intelligent policies
6. **PodDisruptionBudget**: Ensures high availability during cluster operations

### Labels and Selectors

The chart uses standard Kubernetes labels:

- `app.kubernetes.io/name`: Application identifier
- `app.kubernetes.io/component`: Component type (frontend)
- `app.kubernetes.io/instance`: Helm release name
- `app.kubernetes.io/managed-by`: Helm

### ALB Configuration

The ingress is configured for AWS ALB with:

- **Scheme**: `internet-facing` (public internet access)
- **Target Type**: `ip` (direct pod routing)
- **Path Type**: `Prefix` (matches all paths starting with `/`)

## Troubleshooting

### Common Issues

#### Image Pull Errors

If you see image pull errors:

```bash
# Check node IAM permissions for ECR access
kubectl describe pod &lt;pod-name&gt;
```

The node IAM role needs ECR read permissions.

#### ALB Not Created

If the ALB doesn't appear:

1. Verify AWS Load Balancer Controller is installed
2. Check subnet tags for public/private identification
3. Verify IAM permissions for ALB creation

#### Service Not Accessible

If the service isn't reachable:

1. Check pod status: `kubectl get pods`
2. Verify service endpoints: `kubectl get endpoints`
3. Check ingress status: `kubectl describe ingress ingress-2048`

### Cleanup

To remove all resources:

```bash
helm uninstall game-2048
```

## Learning Points

This example demonstrates:

1. **Type-safe Helm templating** with Timonel and custom manifest naming
2. **Multi-environment configuration** with environment-specific scaling policies
3. **Production-ready AWS integration** with ALB, HPA, and PDB
4. **Auto-scaling best practices** with CPU utilization and stabilization windows
5. **High availability patterns** with pod disruption budgets
6. **Custom manifest organization** with descriptive file names
7. **AWS-specific features** showcasing EKS deployment capabilities
8. **Documentation-driven development** with comprehensive comments</content>
    

  </file>
  <file>
    
  
    <path>examples/aws-game-2048/chart.ts</path>
    
  
    <content>// eslint-disable-next-line import/no-unresolved -- Package will be available when published
import { Rutter, valuesRef } from 'timonel';

/**
 * AWS 2048 Game Helm Chart Example
 *
 * This example demonstrates how to use Timonel to create a Helm chart
 * for deploying the AWS 2048 game on EKS with ALB ingress.
 *
 * Based on: https://docs.aws.amazon.com/eks/latest/userguide/auto-elb-example.html
 */

// Create the chart rutter with metadata and values
const rutter = new Rutter({
  meta: {
    name: 'game-2048',
    version: '1.0.0',
    description: 'AWS 2048 game deployment for EKS with ALB ingress',
    appVersion: '1.0.0',
    keywords: ['game', '2048', 'aws', 'eks', 'alb'],
  },
  manifestName: 'game-2048',
  singleManifestFile: false, // Each resource in its own descriptive file
  defaultValues: {
    // Application configuration
    app: {
      name: 'app-2048',
      image: 'public.ecr.aws/l6m2t8p7/docker-2048:latest',
      port: 80,
    },
    // Deployment configuration
    deployment: {
      replicas: 5,
      resources: {
        requests: {
          cpu: '100m',
          memory: '128Mi',
        },
      },
    },
    // Auto-scaling configuration
    autoscaling: {
      enabled: true,
      minReplicas: 2,
      maxReplicas: 10,
      targetCPUUtilization: 70,
    },
    // Service configuration
    service: {
      port: 80,
      targetPort: 80,
    },
    // ALB Ingress configuration
    ingress: {
      enabled: true,
      scheme: 'internet-facing',
      targetType: 'ip',
      healthCheckPath: '/',
    },
  },
  // Environment-specific values
  envValues: {
    dev: {
      deployment: {
        replicas: 2,
      },
      autoscaling: {
        minReplicas: 1,
        maxReplicas: 5,
      },
    },
    staging: {
      deployment: {
        replicas: 3,
      },
      autoscaling: {
        minReplicas: 2,
        maxReplicas: 8,
      },
    },
    prod: {
      deployment: {
        replicas: 5,
      },
      autoscaling: {
        minReplicas: 3,
        maxReplicas: 15,
      },
    },
  },
});

/**
 * Add the 2048 game deployment
 *
 * Creates a Kubernetes Deployment with:
 * - Configurable number of replicas
 * - 2048 game container from public ECR
 * - Resource requests for CPU
 * - Proper labels for service selection
 */
rutter.addDeployment({
  name: valuesRef('app.name') as string,
  image: valuesRef('app.image') as string,
  replicas: 5,
  containerPort: 80,
  resources: {
    requests: {
      cpu: valuesRef('deployment.resources.requests.cpu') as string,
      memory: valuesRef('deployment.resources.requests.memory') as string,
    },
  },
  // Standard Kubernetes labels
  labels: {
    'app.kubernetes.io/component': 'frontend',
  },
  // Pod template labels for service selector
  podLabels: {
    'app.kubernetes.io/name': valuesRef('app.name') as string,
  },
});

/**
 * Add the service to expose the deployment
 *
 * Creates a Kubernetes Service with:
 * - ClusterIP type (default)
 * - Port mapping from service to container
 * - Label selector to find pods
 */
rutter.addService({
  name: 'service-2048',
  ports: [
    {
      port: 80,
      targetPort: 80,
      protocol: 'TCP',
    },
  ],
  selector: {
    'app.kubernetes.io/name': valuesRef('app.name') as string,
  },
});

/**
 * Add AWS ALB Ingress with health checks
 *
 * Creates an AWS Application Load Balancer with:
 * - Internet-facing scheme for public access
 * - IP target type for direct pod routing
 * - Health check configuration
 * - Path-based routing to the service
 */
rutter.addAWSALBIngress({
  name: 'ingress-2048',
  scheme: valuesRef('ingress.scheme') as 'internet-facing' | 'internal',
  targetType: valuesRef('ingress.targetType') as 'ip' | 'instance',
  healthCheckPath: valuesRef('ingress.healthCheckPath') as string,
  healthCheckIntervalSeconds: 30,
  healthyThresholdCount: 2,
  unhealthyThresholdCount: 3,
  tags: {
    Environment: '{{ .Values.global.environment | default &quot;production&quot; }}',
    Application: 'game-2048',
  },
  rules: [
    {
      paths: [
        {
          path: '/',
          pathType: 'Prefix',
          backend: {
            service: {
              name: 'service-2048',
              port: {
                number: 80,
              },
            },
          },
        },
      ],
    },
  ],
});

/**
 * Add Horizontal Pod Autoscaler for automatic scaling
 *
 * Creates an HPA with:
 * - CPU-based scaling at 70% utilization
 * - Configurable min/max replicas per environment
 * - Scaling policies for controlled scale-up/down
 */
rutter.addHorizontalPodAutoscaler({
  name: 'hpa-2048',
  scaleTargetRef: {
    apiVersion: 'apps/v1',
    kind: 'Deployment',
    name: valuesRef('app.name') as string,
  },
  minReplicas: 2,
  maxReplicas: 10,
  metrics: [
    {
      type: 'Resource',
      resource: {
        name: 'cpu',
        target: {
          type: 'Utilization',
          averageUtilization: 70,
        },
      },
    },
  ],
  behavior: {
    scaleUp: {
      stabilizationWindowSeconds: 60,
      policies: [
        {
          type: 'Percent',
          value: 100,
          periodSeconds: 15,
        },
        {
          type: 'Pods',
          value: 2,
          periodSeconds: 60,
        },
      ],
      selectPolicy: 'Max',
    },
    scaleDown: {
      stabilizationWindowSeconds: 300,
      policies: [
        {
          type: 'Percent',
          value: 10,
          periodSeconds: 60,
        },
      ],
    },
  },
});

/**
 * Add Pod Disruption Budget for high availability
 *
 * Ensures at least 1 pod remains available during:
 * - Rolling updates
 * - Node maintenance
 * - Cluster scaling events
 */
rutter.addPodDisruptionBudget({
  name: 'pdb-2048',
  minAvailable: 1,
  selector: {
    matchLabels: {
      'app.kubernetes.io/name': valuesRef('app.name') as string,
    },
  },
});

/**
 * Export the synthesis function
 *
 * This function is called by the Timonel CLI to generate the Helm chart
 */
export default function run(outDir: string) {
  rutter.write(outDir);
}

// Export rutter for --set support
export { rutter };</content>
    

  </file>
  <file>
    
  
    <path>examples/aws-game-2048/package.json</path>
    
  
    <content>{
  &quot;name&quot;: &quot;aws-game-2048-example&quot;,
  &quot;version&quot;: &quot;0.4.0&quot;,
  &quot;description&quot;: &quot;AWS 2048 game Helm chart example using Timonel&quot;,
  &quot;private&quot;: true,
  &quot;scripts&quot;: {
    &quot;build&quot;: &quot;tl synth . ./dist&quot;,
    &quot;package&quot;: &quot;tl package ./dist ./&quot;
  },
  &quot;keywords&quot;: [
    &quot;timonel&quot;,
    &quot;helm&quot;,
    &quot;kubernetes&quot;,
    &quot;aws&quot;,
    &quot;2048&quot;,
    &quot;game&quot;
  ],
  &quot;dependencies&quot;: {
    &quot;timonel&quot;: &quot;^0.4.0&quot;
  }
}</content>
    

  </file>
  <file>
    
  
    <path>examples/wordpress-umbrella/chart.ts</path>
    
  
    <content>// Wrapper for umbrella.ts to work with standard CLI
export { default } from './umbrella';</content>
    

  </file>
  <file>
    
  
    <path>examples/wordpress-umbrella/package.json</path>
    
  
    <content>{
  &quot;name&quot;: &quot;wordpress-umbrella-example&quot;,
  &quot;version&quot;: &quot;0.4.0&quot;,
  &quot;description&quot;: &quot;WordPress umbrella chart example with MySQL and WordPress subcharts&quot;,
  &quot;private&quot;: true,
  &quot;scripts&quot;: {
    &quot;build&quot;: &quot;tl synth . ./dist&quot;,
    &quot;package&quot;: &quot;tl package ./dist ./&quot;
  },
  &quot;keywords&quot;: [
    &quot;timonel&quot;,
    &quot;helm&quot;,
    &quot;kubernetes&quot;,
    &quot;wordpress&quot;,
    &quot;mysql&quot;,
    &quot;umbrella-chart&quot;
  ],
  &quot;dependencies&quot;: {
    &quot;timonel&quot;: &quot;^0.4.0&quot;
  }
}</content>
    

  </file>
  <file>
    
  
    <path>.github/workflows/release.yml</path>
    
  
    <content>name: Automated Release

on:
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch to release from'
        required: true
        default: 'main'
        type: string

permissions:
  contents: write
  packages: write
  id-token: write

jobs:
  check-status:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Check CI Status
        uses: actions/github-script@v7
        with:
          script: |
            const branchRef = '${{ inputs.branch }}'.replace(/[^a-zA-Z0-9\/_.-]/g, '');
            console.log(`Checking status for branch: ${branchRef}`);

            const { data: checks } = await github.rest.checks.listForRef({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: branchRef
            });

            console.log(`Found ${checks.check_runs.length} check runs`);

            const requiredChecks = [
              // Node.js v20 build and test pipeline
              'build (20)',
              // Node.js v22 build and test pipeline
              'build (22)',
              // Security audit and vulnerability scanning
              'security'
            ];
            const failedChecks = [];

            for (const checkName of requiredChecks) {
              const check = checks.check_runs.find(c =&gt; c.name === checkName);
              if (!check) {
                console.log(`‚ùå Missing check: ${checkName}`);
                failedChecks.push(checkName);
              } else if (check.conclusion !== 'success') {
                console.log(`‚ùå Failed check: ${checkName} (${check.conclusion})`);
                failedChecks.push(checkName);
              } else {
                console.log(`‚úÖ Passed check: ${checkName}`);
              }
            }

            if (failedChecks.length &gt; 0) {
              core.setFailed(`Required checks failed: ${failedChecks.join(', ')}`);
            } else {
              console.log('‚úÖ All required checks passed - proceeding with release');
            }

  release:
    runs-on: ubuntu-latest
    environment: npm-prd
    needs: check-status
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          registry-url: 'https://registry.npmjs.org'

      - name: Enable Corepack
        run: corepack enable

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Setup Git
        run: |
          git config --local user.email &quot;action@github.com&quot;
          git config --local user.name &quot;GitHub Action&quot;

      - name: Build and test
        run: |
          pnpm run build
          pnpm run lint
          pnpm run test

      - name: Semantic Release
        run: npx semantic-release
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}</content>
    

  </file>
  <file>
    
  
    <path>.github/workflows/publish.yml</path>
    
  
    <content># Do not modify - Generated with WorkflowForge
name: Publish npm

on:
  release:
    types: [published]

permissions:
  contents: read
  id-token: write

jobs:
  publish:
    runs-on: ubuntu-latest
    if: github.event.release.prerelease == false

    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          persist-credentials: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22
          registry-url: https://registry.npmjs.org

      - name: Enable Corepack
        run: |
          corepack enable
          corepack prepare pnpm@latest --activate

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run security audit
        run: pnpm run security:check

      - name: Lint and typecheck
        run: |
          pnpm run typecheck
          pnpm run lint

      - name: Build package
        run: pnpm run build

      - name: Verify version matches tag
        run: |
          PKG_VERSION=$(node -p &quot;require('./package.json').version&quot;)
          TAG_NAME=&quot;${{ github.event.release.tag_name }}&quot;
          echo &quot;package.json: v${PKG_VERSION} | tag: ${TAG_NAME}&quot;
          if [ &quot;v${PKG_VERSION}&quot; != &quot;${TAG_NAME}&quot; ]; then
            echo &quot;‚ùå Tag and package.json version mismatch&quot; &gt;&amp;2
            exit 1
          fi
          echo &quot;‚úÖ Version verification passed&quot;

      - name: Verify CI success
        uses: actions/github-script@v7
        with:
          script: |
            const sha = process.env.GITHUB_SHA;
            const { owner, repo } = context.repo;
            const res = await github.rest.actions.listWorkflowRuns({
              owner, repo, workflow_id: 'ci.yml', head_sha: sha, per_page: 1
            });
            if (!res.data.workflow_runs.length) {
              core.setFailed(`No CI run found for SHA ${sha}`);
              return;
            }
            const run = res.data.workflow_runs[0];
            if (run.status !== 'completed' || run.conclusion !== 'success') {
              core.setFailed(`CI not successful for ${sha}: status=${run.status} conclusion=${run.conclusion}`);
            }
            console.log('‚úÖ CI verification passed');

      - name: Publish to npm
        run: npm publish --access public --provenance
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}</content>
    

  </file>
  <file>
    
  
    <path>.github/workflows/codeql.yml</path>
    
  
    <content># Do not modify - Generated with WorkflowForge
name: CodeQL
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  schedule:
    - cron: 17 8 * * 4
jobs:
  analyze:
    steps:
      - uses: actions/checkout@v5
        name: Checkout repository
      - uses: github/codeql-action/init@v3
        name: Initialize CodeQL
        with:
          languages: ${{ matrix.language }}
      - uses: github/codeql-action/autobuild@v3
        name: Autobuild
      - uses: github/codeql-action/analyze@v3
        name: Perform CodeQL Analysis
    strategy:
      matrix:
        language:
          - javascript-typescript
    runs-on: ubuntu-latest
permissions:
  contents: read
  security-events: write</content>
    

  </file>
  <file>
    
  
    <path>.github/workflows/ci.yml</path>
    
  
    <content># Do not modify - Generated with WorkflowForge
name: CI
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [20, 22]
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          persist-credentials: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Enable Corepack
        run: |
          corepack enable
          corepack prepare pnpm@latest --activate

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Type check
        run: pnpm run typecheck

      - name: Lint code
        run: pnpm run lint

      - name: Security lint
        run: pnpm run security:lint

      - name: Build project
        run: pnpm run build

      - name: Check formatting
        run: pnpm run format:check

  security:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          persist-credentials: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Enable Corepack
        run: |
          corepack enable
          corepack prepare pnpm@latest --activate

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Security audit
        run: pnpm run security:audit</content>
    

  </file>
  <file>
    
  
    <path>.github/pull_request_template.md</path>
    
  
    <content># Pull Request

## Description

Brief description of the changes in this PR.

## Type of Change

- [ ] üêõ Bug fix (non-breaking change which fixes an issue)
- [ ] ‚ú® New feature (non-breaking change which adds functionality)
- [ ] üí• Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] üìö Documentation update
- [ ] üîß Maintenance (dependency updates, CI improvements, etc.)
- [ ] üîí Security fix

## Changes Made

-
-
-

## Testing

- [ ] Tests pass locally with `pnpm ci:check`
- [ ] New tests added for new functionality (if applicable)
- [ ] Manual testing completed
- [ ] Example updated (if applicable)

## Documentation

- [ ] README updated (if needed)
- [ ] CHANGELOG.md updated
- [ ] JSDoc comments added/updated (if applicable)
- [ ] Example documentation updated (if applicable)

## Security

- [ ] No sensitive information exposed
- [ ] Security implications considered
- [ ] Dependencies reviewed for vulnerabilities

## Breaking Changes

If this is a breaking change, describe what breaks and how to migrate:

```text
N/A
```

## Additional Notes

Any additional information, context, or screenshots that would be helpful for reviewers.

## Checklist

- [ ] Code follows the project's style guidelines
- [ ] Self-review of code completed
- [ ] Code is properly commented
- [ ] Corresponding changes to documentation made
- [ ] No new warnings introduced
- [ ] All CI checks pass</content>
    

  </file>
  <file>
    
  
    <path>.github/ISSUE_TEMPLATE/feature_request.md</path>
    
  
    <content>---
name: Feature request
about: Suggest an idea for this project
title: '[FEATURE] '
labels: enhancement
assignees: ''
---

## Feature Description

A clear and concise description of what you want to happen.

## Problem Statement

Is your feature request related to a problem? Please describe.
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

## Proposed Solution

Describe the solution you'd like.
A clear and concise description of what you want to happen.

## Alternative Solutions

Describe alternatives you've considered.
A clear and concise description of any alternative solutions or features you've considered.

## Use Case

Describe your use case and how this feature would help.

## Example Usage

```typescript
// Example of how the feature would be used
```

## Additional Context

Add any other context or screenshots about the feature request here.

## Implementation Notes

If you have ideas about how this could be implemented, please share them here.</content>
    

  </file>
  <file>
    
  
    <path>.github/ISSUE_TEMPLATE/bug_report.md</path>
    
  
    <content>---
name: Bug report
about: Create a report to help us improve
title: '[BUG] '
labels: bug
assignees: ''
---

## Bug Description

A clear and concise description of what the bug is.

## To Reproduce

Steps to reproduce the behavior:

1. Run command `tl ...`
2. With configuration `...`
3. See error

## Expected Behavior

A clear and concise description of what you expected to happen.

## Actual Behavior

What actually happened instead.

## Environment

- **Timonel version**: [e.g., 0.1.0]
- **Node.js version**: [e.g., 20.10.0]
- **Package manager**: [e.g., pnpm 9.0.0]
- **Operating System**: [e.g., macOS 14.0, Ubuntu 22.04]
- **Kubernetes version**: [e.g., 1.28.0]
- **Helm version**: [e.g., 3.12.0]

## Code Sample

```typescript
// Minimal code sample that reproduces the issue
```

## Error Output

```bash
Paste the full error output here
```

## Additional Context

Add any other context about the problem here, such as:

- Related configuration files
- Screenshots (if applicable)
- Workarounds you've tried</content>
    

  </file>
  <file>
    
  
    <path>.github/dependabot.yml</path>
    
  
    <content>version: 2
updates:
  # Enable version updates for npm
  - package-ecosystem: 'npm'
    directory: '/'
    schedule:
      interval: 'weekly'
      day: 'monday'
      time: '09:00'
    open-pull-requests-limit: 10
    reviewers:
      - 'KenkoGeek'
    assignees:
      - 'KenkoGeek'
    commit-message:
      prefix: 'deps'
      include: 'scope'
    labels:
      - 'dependencies'
      - 'automated'

  # Enable security updates for GitHub Actions
  - package-ecosystem: 'github-actions'
    directory: '/'
    schedule:
      interval: 'weekly'
      day: 'monday'
      time: '09:00'
    open-pull-requests-limit: 5
    reviewers:
      - 'KenkoGeek'
    assignees:
      - 'KenkoGeek'
    commit-message:
      prefix: 'ci'
      include: 'scope'
    labels:
      - 'github-actions'
      - 'automated'</content>
    

  </file>
  <file>
    
  
    <path>.commitlintrc.cjs</path>
    
  
    <content>module.exports = {
  extends: ['@commitlint/config-conventional'],
  rules: {
    'type-enum': [
      2,
      'always',
      [
        'build',
        'chore',
        'ci',
        'docs',
        'feat',
        'fix',
        'perf',
        'refactor',
        'revert',
        'style',
        'test',
        'security',
        'deps',
      ],
    ],
    'scope-enum': [
      2,
      'always',
      ['core', 'cli', 'helm', 'chart', 'rutter', 'k8s', 'security', 'deps', 'ci', 'docs', 'config'],
    ],
    'subject-case': [2, 'never', ['sentence-case', 'start-case', 'pascal-case', 'upper-case']],
    'subject-empty': [2, 'never'],
    'subject-full-stop': [2, 'never', '.'],
    'header-max-length': [2, 'always', 100],
    'body-leading-blank': [2, 'always'],
    'body-max-line-length': [2, 'always', 100],
    'footer-leading-blank': [2, 'always'],
    'footer-max-line-length': [0, 'always'],
  },
};</content>
    

  </file>
  <file>
    
  
    <path>.amazonq/agents/default.json</path>
    
  
    <content>{
  &quot;name&quot;: &quot;default-agent&quot;,
  &quot;version&quot;: &quot;1.0.0&quot;,
  &quot;description&quot;: &quot;Agent configuration&quot;,
  &quot;mcpServers&quot;: {
    &quot;memory&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;disabled&quot;: false,
      &quot;timeout&quot;: 60000,
      &quot;args&quot;: [
        &quot;-y&quot;,
        &quot;@modelcontextprotocol/server-memory&quot;
      ],
      &quot;env&quot;: {
        &quot;MEMORY_FILE_PATH&quot;: &quot;/Users/franklingarcia/Work/Personal/chart-factory/.amazonq/memory.json&quot;
      }
    }
  },
  &quot;tools&quot;: [
    &quot;@memory&quot;
  ],
  &quot;allowedTools&quot;: [
    &quot;@memory/create_entities&quot;,
    &quot;@memory/create_relations&quot;,
    &quot;@memory/add_observations&quot;,
    &quot;@memory/read_graph&quot;,
    &quot;@memory/search_nodes&quot;,
    &quot;@memory/open_nodes&quot;
  ],
  &quot;toolsSettings&quot;: {},
  &quot;includedFiles&quot;: [],
  &quot;resources&quot;: []
}</content>
    

  </file>
  <file>
    
  
    <path>.amazonq/Instrucciones.md</path>
    
  
    <content># Instrucciones

## Desarrollos y mejoras

### Hazlos uno a uno

1. Investiga en las tools de `documentacion` y `browser`.
2. Crea una rama con el fix/feature/etc
3. Desarrolla/modifica.
4. Lint y seguridad (no deshabilites nada por comodidad, resuelve).
5. Prueba con examples/wordpress (cuidado con dejar '../../src' en el import, debes ponerle 'timonel'
   de vuelta).
6. Actualiza README, si y solo s√≠ es necesario, ejemplo: *breaking changes* o *mejora ultra ¬°wow!*.
7. Actualizar Chagelog tomando en cuenta que es algo *ledger*, usa la tool `time` para la fecha del cambio.
8. Analiza el Changelog y README por inconsistencias en el contenido nuevo buscando no este obsoleto
   segun las nuevasfuncionalidades o con alucinaciones, etc..
9. Add y commit.
10. Crea el PR con `gh cli` respondiendo la plantilla dentro de `.github/`.
11. Actualiza tool `memory`.

## Reviews de un PR

1. Obten el ID del PR con `gh cli` y revisa los comentarios/reviews/discussions
2. Lista los que den valor o hagan sentido en base a las mejores practicas.
3. No hagas nada sin la aprobaci√≥n del usuario.

 gh pr view 13 --json reviews --jq '.reviews[] | select(.author.login == &quot;amazon-q-developer&quot;) | .body'
 gh pr view 13 --json comments --jq '.comments[] | select(.author.login == &quot;amazon-q-developer&quot;) | .body'
 gh api repos/:owner/:repo/pulls/13/comments --jq '.[] | select(.user.login == &quot;amazon-q-developer&quot;) | {body: .body, path: .path, line: .line}'
 gh api repos/:owner/:repo/pulls/13/reviews --jq '.[] | select(.user.login == &quot;amazon-q-developer&quot;) | {body: .body, state: .state}'

## GitHub Security Configuration

### Branch Protection (Rulesets)

# Create branch ruleset for main branch protection
gh api repos/:owner/:repo/rulesets \
  --method POST \
  --input - &lt;&lt;&lt; '{
    &quot;name&quot;: &quot;main-protection&quot;,
    &quot;enforcement&quot;: &quot;active&quot;,
    &quot;target&quot;: &quot;branch&quot;,
    &quot;conditions&quot;: {
      &quot;ref_name&quot;: {
        &quot;include&quot;: [&quot;refs/heads/main&quot;],
        &quot;exclude&quot;: []
      }
    },
    &quot;rules&quot;: [
      {
        &quot;type&quot;: &quot;pull_request&quot;,
        &quot;parameters&quot;: {
          &quot;required_approving_review_count&quot;: 1,
          &quot;dismiss_stale_reviews_on_push&quot;: true,
          &quot;require_code_owner_review&quot;: false,
          &quot;require_last_push_approval&quot;: false,
          &quot;required_review_thread_resolution&quot;: false
        }
      },
      {
        &quot;type&quot;: &quot;required_status_checks&quot;,
        &quot;parameters&quot;: {
          &quot;required_status_checks&quot;: [{&quot;context&quot;: &quot;ci&quot;}],
          &quot;strict_required_status_checks_policy&quot;: true
        }
      },
      {&quot;type&quot;: &quot;non_fast_forward&quot;},
      {&quot;type&quot;: &quot;required_linear_history&quot;},
      {
        &quot;type&quot;: &quot;pull_request&quot;,
        &quot;parameters&quot;: {
          &quot;required_approving_review_count&quot;: 1,
          &quot;dismiss_stale_reviews_on_push&quot;: true,
          &quot;require_code_owner_review&quot;: false,
          &quot;require_last_push_approval&quot;: false,
          &quot;required_review_thread_resolution&quot;: false
        }
      }
    ],
    &quot;bypass_actors&quot;: []
  }'

### Repository Settings (Merge Strategy)

# Configure repository to only allow squash merging
gh api repos/:owner/:repo \
  --method PATCH \
  --field allow_squash_merge=true \
  --field allow_merge_commit=false \
  --field allow_rebase_merge=false \
  --field delete_branch_on_merge=true

### Tag Protection (Rulesets) - Replaces deprecated tag protections

# Create tag ruleset for release protection - ONLY CI/CD can create tags
gh api repos/:owner/:repo/rulesets \
  --method POST \
  --input - &lt;&lt;&lt; '{
    &quot;name&quot;: &quot;tag-protection&quot;,
    &quot;enforcement&quot;: &quot;active&quot;,
    &quot;target&quot;: &quot;tag&quot;,
    &quot;conditions&quot;: {
      &quot;ref_name&quot;: {
        &quot;include&quot;: [&quot;refs/tags/v*&quot;],
        &quot;exclude&quot;: []
      }
    },
    &quot;rules&quot;: [
      {&quot;type&quot;: &quot;creation&quot;},
      {&quot;type&quot;: &quot;update&quot;},
      {&quot;type&quot;: &quot;deletion&quot;}
    ],
    &quot;bypass_actors&quot;: [
      {
        &quot;actor_id&quot;: 1,
        &quot;actor_type&quot;: &quot;Integration&quot;,
        &quot;bypass_mode&quot;: &quot;always&quot;
      }
    ]
  }'

# Alternative: Allow only GitHub Actions to bypass
gh api repos/:owner/:repo/rulesets \
  --method POST \
  --input - &lt;&lt;&lt; '{
    &quot;name&quot;: &quot;automated-releases-only&quot;,
    &quot;enforcement&quot;: &quot;active&quot;,
    &quot;target&quot;: &quot;tag&quot;,
    &quot;conditions&quot;: {
      &quot;ref_name&quot;: {
        &quot;include&quot;: [&quot;refs/tags/*&quot;],
        &quot;exclude&quot;: []
      }
    },
    &quot;rules&quot;: [
      {&quot;type&quot;: &quot;creation&quot;},
      {&quot;type&quot;: &quot;update&quot;},
      {&quot;type&quot;: &quot;deletion&quot;}
    ],
    &quot;bypass_actors&quot;: []
  }'

# List existing rulesets
gh api repos/:owner/:repo/rulesets

# View specific ruleset
gh api repos/:owner/:repo/rulesets/{ruleset_id}

## Releases (Manual Workflow Dispatch)

### Manual Release Process (Recommended)
1. Analiza y luego plantea por qu√© la version a liberar, pide revisi√≥n del `usuario` para proseguir.
2. **IMPORTANTE**: Usa **Conventional Commits** con **scopes obligatorios**:
   - Formato: `type(scope): description`
   - Types: feat, fix, docs, style, refactor, perf, test, chore, ci, build, revert
   - Scopes: core, cli, helm, aws, network, umbrella, examples, docs, ci, deps, release
   - Ejemplos:
     * `feat(network): add NetworkPolicy helpers`
     * `fix(core): resolve TypeScript errors`
     * `docs(examples): update WordPress example`
3. **TRIGGER AUTOMATED RELEASE**: GitHub Web UI:
   - Ve a Actions ‚Üí &quot;Automated Release&quot; ‚Üí &quot;Run workflow&quot;
   - Selecciona rama (main)
   - Click &quot;Run workflow&quot; (sin especificar versi√≥n)
4. **Semantic Release** autom√°ticamente:
   - **Analiza commits** desde √∫ltimo release
   - **Calcula versi√≥n** (patch/minor/major) seg√∫n conventional commits
   - **Actualiza package.json** con nueva versi√≥n
   - **Genera CHANGELOG.md** completo con categor√≠as
   - Ejecuta build, lint y tests
   - **Crea commit de release** con `[skip ci]`
   - **Crea y pushea el tag**
   - **Crea GitHub Release** con release notes
   - **Publica a npm** con provenance
5. Actualiza tool `memory`.

### Security Best Practice
- **NEVER create tags manually** - only CI/CD pipeline should create tags
- Use `workflow_dispatch` or push to main to trigger automated releases
- Pipeline uses `GITHUB_TOKEN` with proper permissions to bypass tag protection
- Ensures consistent release process and prevents human error

### Merge Strategy Best Practice
- **ONLY Squash and Merge** enabled for clean history
- **Auto-delete branches** after merge to keep repository clean
- **Linear history** enforced via rulesets
- **One commit per feature** in main branch for easy releases

CRITICO: Siempre investiga con brower y la doc.
CRITICO: Usa las buenas pr√°cticas de desarrollo y convenciones de la industria.
CRITICO: Ingles es el idioma franco para todos los artecfactos, commits, README, Changelog, etc.
CRITICO: Siempre usa las tools/herramientas/mcp para mantener la calidad y disminuir errores.






gh api graphql -f query='
query($owner: String!, $repo: String!, $number: Int!) {
  repository(owner: $owner, name: $repo) {
    pullRequest(number: $number) {
      reviewThreads(first: 50) {
        nodes {
          comments(first: 10) {
            nodes {
              author {
                login
              }
              body
              path
              line
              diffHunk
            }
          }
        }
      }
    }
  }
}' -f owner=KenkoGeek -f repo=timonel -F number=14

## Reply to Inline Comments (Optimized Workflow)

# 1. Get all inline comments with IDs in one call
gh api repos/:owner/:repo/pulls/15/comments --jq '.[] | {path: .path, line: .line, body: .body, comment_id: .id}'

# 2. Reply directly using the comment_id from step 1
gh api repos/:owner/:repo/pulls/15/comments -X POST --field body=&quot;‚úÖ Excellent suggestion! I've implemented the documentation comments exactly as recommended. The requiredChecks array now includes inline comments explaining each check's purpose, which will definitely help with maintainability. Thanks for the detailed feedback!&quot; --field in_reply_to=COMMENT_ID

# 3a. Get thread ID for resolving (different from comment ID)
# NOTE: Review threads only available via GraphQL, not REST API
gh api graphql -f query='
query($owner: String!, $repo: String!, $number: Int!) {
  repository(owner: $owner, name: $repo) {
    pullRequest(number: $number) {
      reviewThreads(first: 50) {
        nodes {
          id
          isResolved
          comments(first: 1) {
            nodes {
              id
              author {
                login
              }
            }
          }
        }
      }
    }
  }
}' -f owner=KenkoGeek -f repo=timonel -F number=15

# 3b. Resolve the comment thread using thread ID (PRRT_*)
gh api graphql -f query='
mutation($threadId: ID!) {
  resolveReviewThread(input: {threadId: $threadId}) {
    thread {
      id
      isResolved
    }
  }
}' -f threadId=THREAD_ID

## Automated Script for Multiple Comments
# Use scripts/handle-pr-comments.sh PR_NUMBER
# Example: bash scripts/handle-pr-comments.sh 14</content>
    

  </file>
  <file>
    
  
    <path>.amazonq/scripts/map-pr-comments.sh</path>
    
  
    <content>#!/bin/bash

# Map PR inline comments to thread IDs using GraphQL only
# Usage: ./map-pr-comments.sh PR_NUMBER [BOT_USER] [OWNER] [REPO]

PR_NUMBER=${1:-14}
BOT_USER=${2:-amazon-q-developer}
OWNER=${3:-KenkoGeek}
REPO=${4:-timonel}

# Get all data from GraphQL API
gh api graphql -f query='
query($owner: String!, $repo: String!, $number: Int!) {
  repository(owner: $owner, name: $repo) {
    pullRequest(number: $number) {
      reviewThreads(first: 50) {
        nodes {
          id
          isResolved
          comments(first: 10) {
            nodes {
              id
              body
              path
              line
              author {
                login
              }
            }
          }
        }
      }
    }
  }
}' -f owner=$OWNER -f repo=$REPO -F number=$PR_NUMBER | jq --arg bot_user &quot;$BOT_USER&quot; --arg pr_number &quot;$PR_NUMBER&quot; --arg owner &quot;$OWNER&quot; --arg repo &quot;$REPO&quot; '
{
  &quot;pr_number&quot;: ($pr_number | tonumber),
  &quot;comments&quot;: [
    .data.repository.pullRequest.reviewThreads.nodes[] |
    . as $thread |
    .comments.nodes[] |
    select(.author.login | startswith($bot_user)) |
    {
      &quot;comment&quot;: {
        &quot;comment_id&quot;: .id,
        &quot;body&quot;: .body,
        &quot;path&quot;: .path,
        &quot;line&quot;: .line
      },
      &quot;thread_id&quot;: $thread.id,
      &quot;answered&quot;: ($thread.comments.nodes | length &gt; 1),
      &quot;resolved&quot;: $thread.isResolved,
      &quot;reply_command&quot;: &quot;gh api repos/\($owner)/\($repo)/pulls/\($pr_number)/comments -X POST --field body=\&quot;REPLY_TEXT\&quot; --field in_reply_to=\(.id)&quot;,
      &quot;resolve_command&quot;: &quot;gh api graphql -f query=\&quot;mutation($threadId: ID!) { resolveReviewThread(input: {threadId: $threadId}) { thread { id isResolved } } }\&quot; -f threadId=\($thread.id)&quot;
    }
  ]
}'</content>
    

  </file>
  <file>
    
  
    <path>tsconfig.json</path>
    
  
    <content>{
  &quot;compilerOptions&quot;: {
    &quot;target&quot;: &quot;ES2020&quot;,
    &quot;module&quot;: &quot;Node16&quot;,
    &quot;declaration&quot;: true,
    &quot;declarationMap&quot;: true,
    &quot;sourceMap&quot;: true,
    &quot;outDir&quot;: &quot;dist&quot;,
    &quot;rootDir&quot;: &quot;src&quot;,
    &quot;strict&quot;: true,
    &quot;noImplicitOverride&quot;: true,
    &quot;noUncheckedIndexedAccess&quot;: true,
    &quot;exactOptionalPropertyTypes&quot;: true,
    &quot;useUnknownInCatchVariables&quot;: true,
    &quot;noFallthroughCasesInSwitch&quot;: true,
    &quot;noPropertyAccessFromIndexSignature&quot;: true,
    &quot;noImplicitReturns&quot;: true,
    &quot;noUnusedLocals&quot;: true,
    &quot;noUnusedParameters&quot;: true,
    &quot;allowUnreachableCode&quot;: false,
    &quot;allowUnusedLabels&quot;: false,
    &quot;esModuleInterop&quot;: true,
    &quot;forceConsistentCasingInFileNames&quot;: true,
    &quot;skipLibCheck&quot;: true,
    &quot;resolveJsonModule&quot;: true,
    &quot;moduleResolution&quot;: &quot;node16&quot;,
    &quot;lib&quot;: [&quot;ES2020&quot;],
    &quot;types&quot;: [&quot;node&quot;]
  },
  &quot;include&quot;: [&quot;src/**/*&quot;],
  &quot;exclude&quot;: [&quot;node_modules&quot;, &quot;dist&quot;]
}</content>
    

  </file>
  <file>
    
  
    <path>.commitlintrc.json</path>
    
  
    <content>{
  &quot;extends&quot;: [&quot;@commitlint/config-conventional&quot;],
  &quot;rules&quot;: {
    &quot;type-enum&quot;: [
      2,
      &quot;always&quot;,
      [&quot;feat&quot;, &quot;fix&quot;, &quot;docs&quot;, &quot;style&quot;, &quot;refactor&quot;, &quot;perf&quot;, &quot;test&quot;, &quot;chore&quot;, &quot;ci&quot;, &quot;build&quot;, &quot;revert&quot;]
    ],
    &quot;scope-empty&quot;: [2, &quot;never&quot;],
    &quot;scope-enum&quot;: [
      2,
      &quot;always&quot;,
      [
        &quot;core&quot;,
        &quot;cli&quot;,
        &quot;helm&quot;,
        &quot;aws&quot;,
        &quot;network&quot;,
        &quot;umbrella&quot;,
        &quot;examples&quot;,
        &quot;docs&quot;,
        &quot;ci&quot;,
        &quot;deps&quot;,
        &quot;release&quot;
      ]
    ]
  }
}</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/requirements.txt</path>
    
  
    <content>workflowforge=1.1.2</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/README.md</path>
    
  
    <content># WorkflowForge Generator

This folder contains a Python-based generator intended to define and emit GitHub Actions workflows.

Note: This generator uses the Python library &quot;workflowforge&quot; to declare pipelines.

## Usage

1. Install Python deps (required; Python 3.11+):

```bash
python3.13 -m venv .venv &amp;&amp; . .venv/bin/activate
pip install -r requirements.txt
```

1. Generate workflows to `.github/workflows/`:

```bash
python3 pipeline.py
```

This outputs:

- `.github/workflows/ci.yml`
- `.github/workflows/codeql.yml`
- `.github/workflows/publish.yml`

## Notes

- The script requires `workflowforge` (from PyPI) and fails if it is missing.
- Keep this folder versioned so the pipeline definition lives close to the code.

### Troubleshooting

- Ensure your virtualenv is active and `pip show workflowforge` succeeds before running the generator.</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/Activate.ps1</path>
    
  
    <content>&lt;#
.Synopsis
Activate a Python virtual environment for the current PowerShell session.

.Description
Pushes the python executable for a virtual environment to the front of the
$Env:PATH environment variable and sets the prompt to signify that you are
in a Python virtual environment. Makes use of the command line switches as
well as the `pyvenv.cfg` file values present in the virtual environment.

.Parameter VenvDir
Path to the directory that contains the virtual environment to activate. The
default value for this is the parent of the directory that the Activate.ps1
script is located within.

.Parameter Prompt
The prompt prefix to display when this virtual environment is activated. By
default, this prompt is the name of the virtual environment folder (VenvDir)
surrounded by parentheses and followed by a single space (ie. '(.venv) ').

.Example
Activate.ps1
Activates the Python virtual environment that contains the Activate.ps1 script.

.Example
Activate.ps1 -Verbose
Activates the Python virtual environment that contains the Activate.ps1 script,
and shows extra information about the activation as it executes.

.Example
Activate.ps1 -VenvDir C:\Users\MyUser\Common\.venv
Activates the Python virtual environment located in the specified location.

.Example
Activate.ps1 -Prompt &quot;MyPython&quot;
Activates the Python virtual environment that contains the Activate.ps1 script,
and prefixes the current prompt with the specified string (surrounded in
parentheses) while the virtual environment is active.

.Notes
On Windows, it may be required to enable this Activate.ps1 script by setting the
execution policy for the user. You can do this by issuing the following PowerShell
command:

PS C:\&gt; Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

For more information on Execution Policies: 
https://go.microsoft.com/fwlink/?LinkID=135170

#&gt;
Param(
    [Parameter(Mandatory = $false)]
    [String]
    $VenvDir,
    [Parameter(Mandatory = $false)]
    [String]
    $Prompt
)

&lt;# Function declarations --------------------------------------------------- #&gt;

&lt;#
.Synopsis
Remove all shell session elements added by the Activate script, including the
addition of the virtual environment's Python executable from the beginning of
the PATH variable.

.Parameter NonDestructive
If present, do not remove this function from the global namespace for the
session.

#&gt;
function global:deactivate ([switch]$NonDestructive) {
    # Revert to original values

    # The prior prompt:
    if (Test-Path -Path Function:_OLD_VIRTUAL_PROMPT) {
        Copy-Item -Path Function:_OLD_VIRTUAL_PROMPT -Destination Function:prompt
        Remove-Item -Path Function:_OLD_VIRTUAL_PROMPT
    }

    # The prior PYTHONHOME:
    if (Test-Path -Path Env:_OLD_VIRTUAL_PYTHONHOME) {
        Copy-Item -Path Env:_OLD_VIRTUAL_PYTHONHOME -Destination Env:PYTHONHOME
        Remove-Item -Path Env:_OLD_VIRTUAL_PYTHONHOME
    }

    # The prior PATH:
    if (Test-Path -Path Env:_OLD_VIRTUAL_PATH) {
        Copy-Item -Path Env:_OLD_VIRTUAL_PATH -Destination Env:PATH
        Remove-Item -Path Env:_OLD_VIRTUAL_PATH
    }

    # Just remove the VIRTUAL_ENV altogether:
    if (Test-Path -Path Env:VIRTUAL_ENV) {
        Remove-Item -Path env:VIRTUAL_ENV
    }

    # Just remove VIRTUAL_ENV_PROMPT altogether.
    if (Test-Path -Path Env:VIRTUAL_ENV_PROMPT) {
        Remove-Item -Path env:VIRTUAL_ENV_PROMPT
    }

    # Just remove the _PYTHON_VENV_PROMPT_PREFIX altogether:
    if (Get-Variable -Name &quot;_PYTHON_VENV_PROMPT_PREFIX&quot; -ErrorAction SilentlyContinue) {
        Remove-Variable -Name _PYTHON_VENV_PROMPT_PREFIX -Scope Global -Force
    }

    # Leave deactivate function in the global namespace if requested:
    if (-not $NonDestructive) {
        Remove-Item -Path function:deactivate
    }
}

&lt;#
.Description
Get-PyVenvConfig parses the values from the pyvenv.cfg file located in the
given folder, and returns them in a map.

For each line in the pyvenv.cfg file, if that line can be parsed into exactly
two strings separated by `=` (with any amount of whitespace surrounding the =)
then it is considered a `key = value` line. The left hand string is the key,
the right hand is the value.

If the value starts with a `'` or a `&quot;` then the first and last character is
stripped from the value before being captured.

.Parameter ConfigDir
Path to the directory that contains the `pyvenv.cfg` file.
#&gt;
function Get-PyVenvConfig(
    [String]
    $ConfigDir
) {
    Write-Verbose &quot;Given ConfigDir=$ConfigDir, obtain values in pyvenv.cfg&quot;

    # Ensure the file exists, and issue a warning if it doesn't (but still allow the function to continue).
    $pyvenvConfigPath = Join-Path -Resolve -Path $ConfigDir -ChildPath 'pyvenv.cfg' -ErrorAction Continue

    # An empty map will be returned if no config file is found.
    $pyvenvConfig = @{ }

    if ($pyvenvConfigPath) {

        Write-Verbose &quot;File exists, parse `key = value` lines&quot;
        $pyvenvConfigContent = Get-Content -Path $pyvenvConfigPath

        $pyvenvConfigContent | ForEach-Object {
            $keyval = $PSItem -split &quot;\s*=\s*&quot;, 2
            if ($keyval[0] -and $keyval[1]) {
                $val = $keyval[1]

                # Remove extraneous quotations around a string value.
                if (&quot;'&quot;&quot;&quot;.Contains($val.Substring(0, 1))) {
                    $val = $val.Substring(1, $val.Length - 2)
                }

                $pyvenvConfig[$keyval[0]] = $val
                Write-Verbose &quot;Adding Key: '$($keyval[0])'='$val'&quot;
            }
        }
    }
    return $pyvenvConfig
}


&lt;# Begin Activate script --------------------------------------------------- #&gt;

# Determine the containing directory of this script
$VenvExecPath = Split-Path -Parent $MyInvocation.MyCommand.Definition
$VenvExecDir = Get-Item -Path $VenvExecPath

Write-Verbose &quot;Activation script is located in path: '$VenvExecPath'&quot;
Write-Verbose &quot;VenvExecDir Fullname: '$($VenvExecDir.FullName)&quot;
Write-Verbose &quot;VenvExecDir Name: '$($VenvExecDir.Name)&quot;

# Set values required in priority: CmdLine, ConfigFile, Default
# First, get the location of the virtual environment, it might not be
# VenvExecDir if specified on the command line.
if ($VenvDir) {
    Write-Verbose &quot;VenvDir given as parameter, using '$VenvDir' to determine values&quot;
}
else {
    Write-Verbose &quot;VenvDir not given as a parameter, using parent directory name as VenvDir.&quot;
    $VenvDir = $VenvExecDir.Parent.FullName.TrimEnd(&quot;\\/&quot;)
    Write-Verbose &quot;VenvDir=$VenvDir&quot;
}

# Next, read the `pyvenv.cfg` file to determine any required value such
# as `prompt`.
$pyvenvCfg = Get-PyVenvConfig -ConfigDir $VenvDir

# Next, set the prompt from the command line, or the config file, or
# just use the name of the virtual environment folder.
if ($Prompt) {
    Write-Verbose &quot;Prompt specified as argument, using '$Prompt'&quot;
}
else {
    Write-Verbose &quot;Prompt not specified as argument to script, checking pyvenv.cfg value&quot;
    if ($pyvenvCfg -and $pyvenvCfg['prompt']) {
        Write-Verbose &quot;  Setting based on value in pyvenv.cfg='$($pyvenvCfg['prompt'])'&quot;
        $Prompt = $pyvenvCfg['prompt'];
    }
    else {
        Write-Verbose &quot;  Setting prompt based on parent's directory's name. (Is the directory name passed to venv module when creating the virtual environment)&quot;
        Write-Verbose &quot;  Got leaf-name of $VenvDir='$(Split-Path -Path $venvDir -Leaf)'&quot;
        $Prompt = Split-Path -Path $venvDir -Leaf
    }
}

Write-Verbose &quot;Prompt = '$Prompt'&quot;
Write-Verbose &quot;VenvDir='$VenvDir'&quot;

# Deactivate any currently active virtual environment, but leave the
# deactivate function in place.
deactivate -nondestructive

# Now set the environment variable VIRTUAL_ENV, used by many tools to determine
# that there is an activated venv.
$env:VIRTUAL_ENV = $VenvDir

$env:VIRTUAL_ENV_PROMPT = $Prompt

if (-not $Env:VIRTUAL_ENV_DISABLE_PROMPT) {

    Write-Verbose &quot;Setting prompt to '$Prompt'&quot;

    # Set the prompt to include the env name
    # Make sure _OLD_VIRTUAL_PROMPT is global
    function global:_OLD_VIRTUAL_PROMPT { &quot;&quot; }
    Copy-Item -Path function:prompt -Destination function:_OLD_VIRTUAL_PROMPT
    New-Variable -Name _PYTHON_VENV_PROMPT_PREFIX -Description &quot;Python virtual environment prompt prefix&quot; -Scope Global -Option ReadOnly -Visibility Public -Value $Prompt

    function global:prompt {
        Write-Host -NoNewline -ForegroundColor Green &quot;($_PYTHON_VENV_PROMPT_PREFIX) &quot;
        _OLD_VIRTUAL_PROMPT
    }
}

# Clear PYTHONHOME
if (Test-Path -Path Env:PYTHONHOME) {
    Copy-Item -Path Env:PYTHONHOME -Destination Env:_OLD_VIRTUAL_PYTHONHOME
    Remove-Item -Path Env:PYTHONHOME
}

# Add the venv to the PATH
Copy-Item -Path Env:PATH -Destination Env:_OLD_VIRTUAL_PATH
$Env:PATH = &quot;$VenvExecDir$([System.IO.Path]::PathSeparator)$Env:PATH&quot;</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/pip3.13</path>
    
  
    <content>#!/Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13/bin/python3.13
import sys
from pip._internal.cli.main import main
if __name__ == '__main__':
    if sys.argv[0].endswith('.exe'):
        sys.argv[0] = sys.argv[0][:-4]
    sys.exit(main())</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/pip3</path>
    
  
    <content>#!/Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13/bin/python3.13
import sys
from pip._internal.cli.main import main
if __name__ == '__main__':
    if sys.argv[0].endswith('.exe'):
        sys.argv[0] = sys.argv[0][:-4]
    sys.exit(main())</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/activate.fish</path>
    
  
    <content># This file must be used with &quot;source &lt;venv&gt;/bin/activate.fish&quot; *from fish*
# (https://fishshell.com/). You cannot run it directly.

function deactivate  -d &quot;Exit virtual environment and return to normal shell environment&quot;
    # reset old environment variables
    if test -n &quot;$_OLD_VIRTUAL_PATH&quot;
        set -gx PATH $_OLD_VIRTUAL_PATH
        set -e _OLD_VIRTUAL_PATH
    end
    if test -n &quot;$_OLD_VIRTUAL_PYTHONHOME&quot;
        set -gx PYTHONHOME $_OLD_VIRTUAL_PYTHONHOME
        set -e _OLD_VIRTUAL_PYTHONHOME
    end

    if test -n &quot;$_OLD_FISH_PROMPT_OVERRIDE&quot;
        set -e _OLD_FISH_PROMPT_OVERRIDE
        # prevents error when using nested fish instances (Issue #93858)
        if functions -q _old_fish_prompt
            functions -e fish_prompt
            functions -c _old_fish_prompt fish_prompt
            functions -e _old_fish_prompt
        end
    end

    set -e VIRTUAL_ENV
    set -e VIRTUAL_ENV_PROMPT
    if test &quot;$argv[1]&quot; != &quot;nondestructive&quot;
        # Self-destruct!
        functions -e deactivate
    end
end

# Unset irrelevant variables.
deactivate nondestructive

set -gx VIRTUAL_ENV /Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13

set -gx _OLD_VIRTUAL_PATH $PATH
set -gx PATH &quot;$VIRTUAL_ENV/&quot;bin $PATH
set -gx VIRTUAL_ENV_PROMPT .venv-3.13

# Unset PYTHONHOME if set.
if set -q PYTHONHOME
    set -gx _OLD_VIRTUAL_PYTHONHOME $PYTHONHOME
    set -e PYTHONHOME
end

if test -z &quot;$VIRTUAL_ENV_DISABLE_PROMPT&quot;
    # fish uses a function instead of an env var to generate the prompt.

    # Save the current fish_prompt function as the function _old_fish_prompt.
    functions -c fish_prompt _old_fish_prompt

    # With the original prompt function renamed, we can override with our own.
    function fish_prompt
        # Save the return status of the last command.
        set -l old_status $status

        # Output the venv prompt; color taken from the blue of the Python logo.
        printf &quot;%s(%s)%s &quot; (set_color 4B8BBE) .venv-3.13 (set_color normal)

        # Restore the return status of the previous command.
        echo &quot;exit $old_status&quot; | .
        # Output the original/&quot;old&quot; prompt.
        _old_fish_prompt
    end

    set -gx _OLD_FISH_PROMPT_OVERRIDE &quot;$VIRTUAL_ENV&quot;
end</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/pip</path>
    
  
    <content>#!/Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13/bin/python3.13
import sys
from pip._internal.cli.main import main
if __name__ == '__main__':
    if sys.argv[0].endswith('.exe'):
        sys.argv[0] = sys.argv[0][:-4]
    sys.exit(main())</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/activate</path>
    
  
    <content># This file must be used with &quot;source bin/activate&quot; *from bash*
# You cannot run it directly

deactivate () {
    # reset old environment variables
    if [ -n &quot;${_OLD_VIRTUAL_PATH:-}&quot; ] ; then
        PATH=&quot;${_OLD_VIRTUAL_PATH:-}&quot;
        export PATH
        unset _OLD_VIRTUAL_PATH
    fi
    if [ -n &quot;${_OLD_VIRTUAL_PYTHONHOME:-}&quot; ] ; then
        PYTHONHOME=&quot;${_OLD_VIRTUAL_PYTHONHOME:-}&quot;
        export PYTHONHOME
        unset _OLD_VIRTUAL_PYTHONHOME
    fi

    # Call hash to forget past locations. Without forgetting
    # past locations the $PATH changes we made may not be respected.
    # See &quot;man bash&quot; for more details. hash is usually a builtin of your shell
    hash -r 2&gt; /dev/null

    if [ -n &quot;${_OLD_VIRTUAL_PS1:-}&quot; ] ; then
        PS1=&quot;${_OLD_VIRTUAL_PS1:-}&quot;
        export PS1
        unset _OLD_VIRTUAL_PS1
    fi

    unset VIRTUAL_ENV
    unset VIRTUAL_ENV_PROMPT
    if [ ! &quot;${1:-}&quot; = &quot;nondestructive&quot; ] ; then
    # Self destruct!
        unset -f deactivate
    fi
}

# unset irrelevant variables
deactivate nondestructive

# on Windows, a path can contain colons and backslashes and has to be converted:
case &quot;$(uname)&quot; in
    CYGWIN*|MSYS*|MINGW*)
        # transform D:\path\to\venv to /d/path/to/venv on MSYS and MINGW
        # and to /cygdrive/d/path/to/venv on Cygwin
        VIRTUAL_ENV=$(cygpath /Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13)
        export VIRTUAL_ENV
        ;;
    *)
        # use the path as-is
        export VIRTUAL_ENV=/Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13
        ;;
esac

_OLD_VIRTUAL_PATH=&quot;$PATH&quot;
PATH=&quot;$VIRTUAL_ENV/&quot;bin&quot;:$PATH&quot;
export PATH

VIRTUAL_ENV_PROMPT=.venv-3.13
export VIRTUAL_ENV_PROMPT

# unset PYTHONHOME if set
# this will fail if PYTHONHOME is set to the empty string (which is bad anyway)
# could use `if (set -u; : $PYTHONHOME) ;` in bash
if [ -n &quot;${PYTHONHOME:-}&quot; ] ; then
    _OLD_VIRTUAL_PYTHONHOME=&quot;${PYTHONHOME:-}&quot;
    unset PYTHONHOME
fi

if [ -z &quot;${VIRTUAL_ENV_DISABLE_PROMPT:-}&quot; ] ; then
    _OLD_VIRTUAL_PS1=&quot;${PS1:-}&quot;
    PS1=&quot;(&quot;.venv-3.13&quot;) ${PS1:-}&quot;
    export PS1
fi

# Call hash to forget past commands. Without forgetting
# past commands the $PATH changes we made may not be respected
hash -r 2&gt; /dev/null</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/normalizer</path>
    
  
    <content>#!/Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13/bin/python3.13
import sys
from charset_normalizer.cli import cli_detect
if __name__ == '__main__':
    if sys.argv[0].endswith('.exe'):
        sys.argv[0] = sys.argv[0][:-4]
    sys.exit(cli_detect())</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/bin/activate.csh</path>
    
  
    <content># This file must be used with &quot;source bin/activate.csh&quot; *from csh*.
# You cannot run it directly.

# Created by Davide Di Blasi &lt;davidedb@gmail.com&gt;.
# Ported to Python 3.3 venv by Andrew Svetlov &lt;andrew.svetlov@gmail.com&gt;

alias deactivate 'test $?_OLD_VIRTUAL_PATH != 0 &amp;&amp; setenv PATH &quot;$_OLD_VIRTUAL_PATH&quot; &amp;&amp; unset _OLD_VIRTUAL_PATH; rehash; test $?_OLD_VIRTUAL_PROMPT != 0 &amp;&amp; set prompt=&quot;$_OLD_VIRTUAL_PROMPT&quot; &amp;&amp; unset _OLD_VIRTUAL_PROMPT; unsetenv VIRTUAL_ENV; unsetenv VIRTUAL_ENV_PROMPT; test &quot;\!:*&quot; != &quot;nondestructive&quot; &amp;&amp; unalias deactivate'

# Unset irrelevant variables.
deactivate nondestructive

setenv VIRTUAL_ENV /Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13

set _OLD_VIRTUAL_PATH=&quot;$PATH&quot;
setenv PATH &quot;$VIRTUAL_ENV/&quot;bin&quot;:$PATH&quot;
setenv VIRTUAL_ENV_PROMPT .venv-3.13


set _OLD_VIRTUAL_PROMPT=&quot;$prompt&quot;

if (! &quot;$?VIRTUAL_ENV_DISABLE_PROMPT&quot;) then
    set prompt = &quot;(&quot;.venv-3.13&quot;) $prompt:q&quot;
endif

alias pydoc python -m pydoc

rehash</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/pyvenv.cfg</path>
    
  
    <content>home = /opt/homebrew/opt/python@3.13/bin
include-system-site-packages = false
version = 3.13.7
executable = /opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/bin/python3.13
command = /opt/homebrew/opt/python@3.13/bin/python3.13 -m venv /Users/franklingarcia/Work/Personal/chart-factory/.workflowforge/.venv-3.13</content>
    

  </file>
  <file>
    
  
    <path>.workflowforge/.venv-3.13/.gitignore</path>
    
  
    <content># Created by venv; see https://docs.python.org/3/library/venv.html
*</content>
    

  </file>
  <file>
    
  
    <path>eslint.config.js</path>
    
  
    <content>import js from '@eslint/js';
import tseslint from '@typescript-eslint/eslint-plugin';
import tsparser from '@typescript-eslint/parser';
import importPlugin from 'eslint-plugin-import';
import unusedImports from 'eslint-plugin-unused-imports';
import sonarjs from 'eslint-plugin-sonarjs';
import security from 'eslint-plugin-security';

export default [
  js.configs.recommended,
  {
    files: ['**/*.{ts,tsx}'],
    languageOptions: {
      parser: tsparser,
      parserOptions: {
        ecmaVersion: 'latest',
        sourceType: 'module',
      },
      globals: {
        console: 'readonly',
        process: 'readonly',
        __dirname: 'readonly',
        require: 'readonly',
        Buffer: 'readonly',
      },
    },
    plugins: {
      '@typescript-eslint': tseslint,
      import: importPlugin,
      'unused-imports': unusedImports,
      sonarjs,
      security,
    },
    rules: {
      ...tseslint.configs.recommended.rules,
      'no-console': 'off',
      'unused-imports/no-unused-imports': 'error',
      '@typescript-eslint/no-unused-vars': [
        'error',
        { argsIgnorePattern: '^_', varsIgnorePattern: '^_' },
      ],
      '@typescript-eslint/consistent-type-imports': ['error', { prefer: 'type-imports' }],
      'import/order': [
        'warn',
        {
          groups: ['builtin', 'external', 'internal', 'parent', 'sibling', 'index'],
          'newlines-between': 'always',
        },
      ],
      // SonarJS rules
      'sonarjs/cognitive-complexity': ['error', 15],
      'sonarjs/no-collapsible-if': 'error',
      'sonarjs/no-duplicate-string': 'error',
      'sonarjs/no-duplicated-branches': 'error',
      'sonarjs/no-identical-functions': 'error',
      'sonarjs/no-redundant-boolean': 'error',
      'sonarjs/no-unused-collection': 'error',
      'sonarjs/prefer-immediate-return': 'error',
      // Security rules
      'security/detect-object-injection': 'error',
      'security/detect-non-literal-regexp': 'error',
      'security/detect-unsafe-regex': 'error',
      'security/detect-buffer-noassert': 'error',
      'security/detect-child-process': 'error',
      'security/detect-disable-mustache-escape': 'error',
      'security/detect-eval-with-expression': 'error',
      'security/detect-no-csrf-before-method-override': 'error',
      'security/detect-non-literal-fs-filename': 'warn',
      'security/detect-non-literal-require': 'warn',
      'security/detect-possible-timing-attacks': 'warn',
      'security/detect-pseudoRandomBytes': 'error',
    },
    settings: {
      'import/resolver': {
        typescript: true,
      },
    },
  },
  {
    files: ['src/cli.ts', 'src/lib/UmbrellaRutter.ts'],
    rules: {
      '@typescript-eslint/no-var-requires': 'off',
      '@typescript-eslint/no-require-imports': 'off',
    },
  },
  {
    ignores: ['examples/**', 'dist/**', 'node_modules/**', '.workflowforge/**', '.pnpm-store/**'],
  },
];</content>
    

  </file>
  <file>
    
  
    <path>.markdownlint.json</path>
    
  
    <content>{
  &quot;default&quot;: true,
  &quot;MD013&quot;: {
    &quot;line_length&quot;: 100,
    &quot;code_blocks&quot;: false,
    &quot;tables&quot;: false
  },
  &quot;MD033&quot;: false
}</content>
    

  </file>
  <file>
    
  
    <path>SECURITY.md</path>
    
  
    <content># Security Policy

## Reporting Security Vulnerabilities

- **DO NOT** create public GitHub issues for security vulnerabilities
- Report vulnerabilities privately via project maintainers or GitHub Security Advisories
- Include detailed information about the vulnerability and steps to reproduce
- We aim to triage within 5 business days and provide updates within 10 business days

## Supported Versions

| Version | Supported          |
| ------- | ------------------ |
| 0.1.x   | :white_check_mark: |

## Development Security

### Static Analysis

- TypeScript strict mode enabled with comprehensive compiler checks
- ESLint with security plugin (`eslint-plugin-security`) in CI/CD
- SonarJS plugin for code quality and security analysis
- Automated dependency vulnerability scanning via `pnpm audit`

### Dependencies

- Regular dependency updates via Dependabot
- Security-focused dependency management
- No runtime network calls in library APIs
- Minimal dependency footprint

### CI/CD Security

- GitHub Actions with minimal permissions
- Dependency caching with integrity checks
- Automated security audits on every build
- CodeQL analysis for vulnerability detection

### Best Practices

- Input validation and sanitization
- Secure coding practices following OWASP guidelines
- Regular security reviews of code changes
- Principle of least privilege in all configurations</content>
    

  </file>
  <file>
    
  
    <path>src/cli.ts</path>
    
  
    <content>#!/usr/bin/env node
import * as fs from 'fs';
import * as path from 'path';
import * as cp from 'child_process';

const HELM_INSTALL_URL = 'https://helm.sh/docs/intro/install/';
const HELM_ENV_VAR_MSG = 'Or set HELM_BIN environment variable to helm binary path.';

function usageAndExit(msg?: string): never {
  if (msg) console.error(msg);
  console.log(
    [
      'timonel (tl) - programmatic Helm chart generator',
      '',
      'Usage:',
      '  tl init &lt;chart-name&gt;                 Scaffold example at charts/&lt;name&gt;/chart.ts',
      '  tl synth &lt;projectDir&gt; [outDir]       Run charts/&lt;...&gt;/chart.ts and write chart',
      '  tl validate &lt;projectDir&gt;             Validate chart.ts without generating files',
      '  tl diff &lt;projectDir&gt; &lt;chartDir&gt;      Compare generated chart with existing',
      '  tl deploy &lt;projectDir&gt; &lt;release&gt;     Synth and deploy with helm install/upgrade',
      '  tl package &lt;chartDir&gt; [outDir]       Run `helm package` into outDir (requires Helm)',
      '',
      'Umbrella Charts:',
      '  tl umbrella init &lt;name&gt;              Create umbrella chart structure',
      '  tl umbrella add &lt;subchart&gt;           Add subchart to umbrella',
      '  tl umbrella synth [outDir]           Generate umbrella chart',
      '',
      'Flags:',
      '  --dry-run                            Show what would be done without executing',
      '  --silent                             Suppress output (useful for CI)',
      '  --env &lt;environment&gt;                  Use environment-specific values',
      '  --set &lt;key=value&gt;                    Override values (can be used multiple times)',
      '  --version, -v                        Show version information',
      '',
      'Examples:',
      '  tl init my-app',
      '  tl synth charts/my-app charts/my-app/dist',
      '  tl validate charts/my-app',
      '  tl deploy charts/my-app my-release --env prod',
      '  tl synth charts/my-app --dry-run --silent',
      '  tl synth charts/my-app --set replicas=5 --set image.tag=v2.0.0',
      '  tl deploy charts/my-app my-release --set service.port=8080',
    ].join('\n'),
  );
  process.exit(msg ? 1 : 0);
}

async function cmdInit(name?: string, silent = false) {
  if (!name) usageAndExit('Missing &lt;chart-name&gt;');
  const base = path.join(process.cwd(), 'charts', name as string);
  const file = path.join(base, 'chart.ts');
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(base, { recursive: true });
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  if (fs.existsSync(file)) {
    console.error(`File already exists: ${file}`);
    process.exit(1);
  }
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.writeFileSync(file, exampleChartTs(name));
  log(`Scaffold created at ${file}`, silent);
}

async function cmdValidate(projectDir?: string, silent = false) {
  if (!projectDir) usageAndExit('Missing &lt;projectDir&gt;');
  const proj = projectDir as string;
  const chartTs = path.isAbsolute(proj)
    ? path.join(proj, 'chart.ts')
    : path.join(process.cwd(), proj, 'chart.ts');
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  if (!fs.existsSync(chartTs)) {
    console.error(`chart.ts not found at ${chartTs}`);
    process.exit(1);
  }

  // Check if helm is available
  const helm = process.env['HELM_BIN'] || 'helm';
  try {
    cp.execSync(`${helm} version --short`, { stdio: 'ignore' });
  } catch {
    console.error('‚úó Helm not found. Install Helm to enable chart validation.');
    console.error(`  Install: ${HELM_INSTALL_URL}`);
    console.error(`  ${HELM_ENV_VAR_MSG}`);
    process.exit(1);
  }

  const tempDir = path.join(process.cwd(), '.timonel-validate');
  try {
    // Generate chart to temp directory for validation
    await cmdSynth(projectDir, tempDir, { dryRun: false, silent: true, set: {} });

    // Run helm lint on generated chart
    const lintResult = cp.spawnSync(helm, ['lint', tempDir], {
      stdio: silent ? 'pipe' : 'inherit',
      encoding: 'utf8',
    });

    if (lintResult.status !== 0) {
      if (silent &amp;&amp; lintResult.stderr) {
        console.error(lintResult.stderr);
      }
      console.error('‚úó Chart validation failed: Helm lint errors found');
      process.exit(1);
    }

    log('‚úì Chart validation passed', silent);
  } catch (error) {
    console.error('‚úó Chart validation failed:', error instanceof Error ? error.message : error);
    process.exit(1);
  } finally {
    // Cleanup temp directory

    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }
  }
}

async function cmdSynth(projectDir?: string, out?: string, flags?: CliFlags) {
  if (!projectDir) usageAndExit('Missing &lt;projectDir&gt;');
  const proj = projectDir as string;
  const chartTs = path.isAbsolute(proj)
    ? path.join(proj, 'chart.ts')
    : path.join(process.cwd(), proj, 'chart.ts');
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  if (!fs.existsSync(chartTs)) {
    console.error(`chart.ts not found at ${chartTs}`);
    process.exit(1);
  }
  // Enable TS runtime with specific config
  require('ts-node').register({
    transpileOnly: true,
    compilerOptions: {
      module: 'CommonJS',
      moduleResolution: 'node',
    },
  });
  // Validate module path to prevent code injection
  const allowedPaths = [process.cwd()];
  const resolvedPath = path.resolve(chartTs);
  if (!allowedPaths.some((allowedPath) =&gt; resolvedPath.startsWith(allowedPath))) {
    console.error('Module path must be within current working directory');
    process.exit(1);
  }

  // eslint-disable-next-line security/detect-non-literal-require -- CLI tool needs dynamic module loading
  const mod = require(resolvedPath);
  const runner = mod.default || mod.run || mod.synth;
  if (typeof runner !== 'function') {
    console.error('chart.ts must export a default/run/synth function');
    process.exit(1);
  }

  // Apply --set overrides if provided
  if (
    flags?.set &amp;&amp;
    Object.keys(flags.set).length &gt; 0 &amp;&amp;
    mod.rutter &amp;&amp;
    typeof mod.rutter.setValues === 'function'
  ) {
    mod.rutter.setValues(flags.set);
  }
  const outDir = out || path.join(path.dirname(chartTs), 'dist');

  if (flags?.dryRun) {
    log(`[DRY RUN] Would write chart to ${outDir}`, flags.silent);
    return;
  }

  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(outDir, { recursive: true });
  await Promise.resolve(runner(outDir));
  log(`Chart written to ${outDir}`, flags?.silent);
}

async function cmdDiff(projectDir?: string, chartDir?: string, silent = false) {
  if (!projectDir || !chartDir) usageAndExit('Missing &lt;projectDir&gt; or &lt;chartDir&gt;');

  const tempDir = path.join(process.cwd(), '.timonel-temp');
  try {
    // Generate chart to temp directory
    await cmdSynth(projectDir, tempDir);

    // Compare with existing chart
    const diffCmd = process.platform === 'win32' ? 'fc' : 'diff';
    const args =
      process.platform === 'win32' ? ['/N', chartDir, tempDir] : ['-r', chartDir, tempDir];

    log(`&gt; ${diffCmd} ${args.join(' ')}`, silent);
    const res = cp.spawnSync(diffCmd, args, { stdio: 'inherit' });

    if (res.status === 0) {
      log('‚úì No differences found', silent);
    } else if (res.status === 1) {
      log('‚ö† Differences found', silent);
      process.exit(1);
    }
  } finally {
    // Cleanup temp directory

    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }
  }
}

async function cmdDeploy(projectDir?: string, releaseName?: string, flags?: CliFlags) {
  if (!projectDir || !releaseName) usageAndExit('Missing &lt;projectDir&gt; or &lt;release&gt;');

  // Check if helm is available
  const helm = process.env['HELM_BIN'] || 'helm';
  try {
    cp.execSync(`${helm} version --short`, { stdio: 'ignore' });
  } catch {
    console.error('‚úó Helm not found. Install Helm to enable deployment.');
    console.error(`  Install: ${HELM_INSTALL_URL}`);
    console.error(`  ${HELM_ENV_VAR_MSG}`);
    process.exit(1);
  }

  const tempDir = path.join(process.cwd(), '.timonel-deploy');
  try {
    // Generate chart
    await cmdSynth(projectDir, tempDir, flags);

    // Check if release exists
    const checkCmd = `${helm} status ${releaseName}`;
    const releaseExists = cp.spawnSync('sh', ['-c', checkCmd], { stdio: 'ignore' }).status === 0;

    // Build helm command
    const action = releaseExists ? 'upgrade' : 'install';
    const args = [action, releaseName, tempDir];

    // Add environment-specific values if specified
    if (flags?.env) {
      const valuesFile = path.join(tempDir, `values-${flags.env}.yaml`);
      // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
      if (fs.existsSync(valuesFile)) {
        args.push('-f', valuesFile);
      }
    }

    if (flags?.dryRun) {
      args.push('--dry-run');
    }

    log(`&gt; ${helm} ${args.join(' ')}`, flags?.silent);
    const res = cp.spawnSync(helm, args, { stdio: 'inherit' });

    if (res.status !== 0) {
      process.exit(res.status ?? 1);
    }

    log(`‚úì ${action === 'install' ? 'Deployed' : 'Updated'} release ${releaseName}`, flags?.silent);
  } finally {
    // Cleanup temp directory

    if (fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
    }
  }
}

async function cmdUmbrella(subcommand?: string, args?: string[], flags?: CliFlags) {
  const UMBRELLA_USAGE_MSG = 'Missing umbrella subcommand (init|add|synth)';
  if (!subcommand) usageAndExit(UMBRELLA_USAGE_MSG);

  switch (subcommand) {
    case 'init':
      await cmdUmbrellaInit(args?.[0], flags?.silent);
      break;
    case 'add':
      await cmdUmbrellaAdd(args?.[0], flags?.silent);
      break;
    case 'synth':
      await cmdUmbrellaSynth(args?.[0], flags);
      break;
    default:
      usageAndExit(`Unknown umbrella subcommand: ${subcommand}`);
  }
}

const UMBRELLA_CONFIG_FILE = 'umbrella.config.json';

async function cmdUmbrellaInit(name?: string, silent = false) {
  const MISSING_NAME_MSG = 'Missing umbrella chart name';
  if (!name) usageAndExit(MISSING_NAME_MSG);

  const base = path.join(process.cwd(), name);
  const umbrellaFile = path.join(base, 'umbrella.ts');
  const configFile = path.join(base, UMBRELLA_CONFIG_FILE);

  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(base, { recursive: true });
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(path.join(base, 'charts'), { recursive: true });

  // Create umbrella.ts
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.writeFileSync(umbrellaFile, exampleUmbrellaTs(name));

  // Create config file
  const config = {
    name,
    version: '0.1.0',
    description: `${name} umbrella chart`,
    subcharts: [],
  };
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.writeFileSync(configFile, JSON.stringify(config, null, 2));

  log(`Umbrella chart structure created at ${base}`, silent);
  log(`Add subcharts with: tl umbrella add &lt;subchart-name&gt;`, silent);
}

async function cmdUmbrellaAdd(subchartName?: string, silent = false) {
  const MISSING_SUBCHART_MSG = 'Missing subchart name';
  if (!subchartName) usageAndExit(MISSING_SUBCHART_MSG);

  const configFile = path.join(process.cwd(), UMBRELLA_CONFIG_FILE);

  if (!fs.existsSync(configFile)) {
    console.error(`${UMBRELLA_CONFIG_FILE} not found. Run \`tl umbrella init\` first.`);
    process.exit(1);
  }

  const config = JSON.parse(fs.readFileSync(configFile, 'utf8'));

  // Create subchart directory and scaffold
  const subchartDir = path.join(process.cwd(), 'charts', subchartName);
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(subchartDir, { recursive: true });

  const chartFile = path.join(subchartDir, 'chart.ts');
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.writeFileSync(chartFile, exampleSubchartTs(subchartName));

  // Update config
  config.subcharts.push({
    name: subchartName,
    version: '0.1.0',
    path: `./charts/${subchartName}/chart.ts`,
  });

  fs.writeFileSync(configFile, JSON.stringify(config, null, 2));

  log(`Subchart ${subchartName} added to umbrella`, silent);
}

async function cmdUmbrellaSynth(outDir?: string, flags?: CliFlags) {
  const configFile = path.join(process.cwd(), UMBRELLA_CONFIG_FILE);

  if (!fs.existsSync(configFile)) {
    console.error(`${UMBRELLA_CONFIG_FILE} not found. Run \`tl umbrella init\` first.`);
    process.exit(1);
  }

  const umbrellaFile = path.join(process.cwd(), 'umbrella.ts');

  if (!fs.existsSync(umbrellaFile)) {
    console.error('umbrella.ts not found.');
    process.exit(1);
  }

  // Enable TS runtime
  require('ts-node').register({
    transpileOnly: true,
    compilerOptions: {
      module: 'CommonJS',
      moduleResolution: 'node',
    },
  });

  // Validate module path to prevent code injection
  const allowedPaths = [process.cwd()];
  const resolvedPath = path.resolve(umbrellaFile);
  if (!allowedPaths.some((allowedPath) =&gt; resolvedPath.startsWith(allowedPath))) {
    console.error('Module path must be within current working directory');
    process.exit(1);
  }

  const mod = require(resolvedPath);
  const runner = mod.default || mod.run || mod.synth;
  if (typeof runner !== 'function') {
    console.error('umbrella.ts must export a default/run/synth function');
    process.exit(1);
  }

  const output = outDir || path.join(process.cwd(), 'dist');

  if (flags?.dryRun) {
    log(`[DRY RUN] Would write umbrella chart to ${output}`, flags.silent);
    return;
  }

  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(output, { recursive: true });
  await Promise.resolve(runner(output));
  log(`Umbrella chart written to ${output}`, flags?.silent);
}

async function cmdPackage(chartDir?: string, out?: string, silent = false) {
  if (!chartDir) usageAndExit('Missing &lt;chartDir&gt;');
  const src = path.isAbsolute(chartDir) ? chartDir : path.join(process.cwd(), chartDir);
  const chartYaml = path.join(src, 'Chart.yaml');
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  if (!fs.existsSync(chartYaml)) {
    console.error(`Chart.yaml not found in ${src}`);
    process.exit(1);
  }
  const outDir = out ? (path.isAbsolute(out) ? out : path.join(process.cwd(), out)) : src;
  // eslint-disable-next-line security/detect-non-literal-fs-filename -- CLI tool needs dynamic paths
  fs.mkdirSync(outDir, { recursive: true });
  const helm = process.env['HELM_BIN'] || 'helm';
  const args = ['package', src, '-d', outDir];
  log(`&gt; ${helm} ${args.join(' ')}`, silent);
  const res = cp.spawnSync(helm, args, { stdio: 'inherit' });
  if (res.error) {
    console.error(`‚úó Failed to execute Helm: ${res.error.message}`);
    console.error(`  Install: ${HELM_INSTALL_URL}`);
    console.error(`  ${HELM_ENV_VAR_MSG}`);
    process.exit(1);
  }
  if (res.status !== 0) {
    process.exit(res.status ?? 1);
  }
}

function exampleUmbrellaTs(name: string): string {
  return `import { createUmbrella } from 'timonel';
import { Rutter } from 'timonel';

// Import subcharts (these will be created with 'tl umbrella add')
// import { rutter as fluentBit } from './charts/fluent-bit/chart';
// import { rutter as openObserve } from './charts/openobserve/chart';

// Create umbrella chart
const umbrella = createUmbrella({
  meta: {
    name: '${name}',
    version: '0.1.0',
    description: '${name} umbrella chart',
    appVersion: '1.0.0',
  },
  subcharts: [
    // Add your subcharts here:
    // { name: 'fluent-bit', rutter: fluentBit },
    // { name: 'openobserve', rutter: openObserve },
  ],
  defaultValues: {
    global: {
      // Global values shared across subcharts
    },
  },
  envValues: {
    dev: {
      // Development environment overrides
    },
    prod: {
      // Production environment overrides
    },
  },
});

export default function run(outDir: string) {
  umbrella.write(outDir);
}
`;
}

function exampleSubchartTs(name: string): string {
  return `import { Rutter } from '../../../src';
import { valuesRef } from '../../../src/lib/helm';

// Define subchart
const rutter = new Rutter({
  meta: {
    name: '${name}',
    version: '0.1.0',
    description: '${name} subchart',
    appVersion: '1.0.0',
  },
  defaultValues: {
    image: { repository: 'nginx', tag: '1.27' },
    replicas: 1,
    service: { port: 80 },
  },
});

// Add resources
rutter.addDeployment({
  name: '${name}',
  image: String(valuesRef('image.repository')) + ':' + String(valuesRef('image.tag')),
  replicas: 1,
  containerPort: 80,
});

rutter.addService({
  name: '${name}',
  ports: [{ port: 80, targetPort: 80 }],
  selector: { app: '${name}' },
});

export default function run(outDir: string) {
  rutter.write(outDir);
}

// Export rutter for umbrella chart
export { rutter };
`;
}

function exampleChartTs(name: string): string {
  return `import { Rutter } from '../../src';
import { valuesRef, helm } from '../../src/lib/helm';

// Define chart metadata and default/env values
const rutter = new Rutter({
  meta: {
    name: '${name}',
    version: '0.1.0',
    description: 'Example Helm chart generated with timonel + cdk8s',
    appVersion: '1.0.0',
  },
  defaultValues: {
    image: { repository: 'nginx', tag: '1.27' },
    replicas: 1,
    service: { port: 80 },
    ingress: { enabled: false, host: 'example.com', className: 'nginx' },
  },
  envValues: {
    dev: { replicas: 1 },
    prod: { replicas: 3 },
  },
});

// Use Helm placeholders in strings passed to cdk8s constructs
rutter.addDeployment({
  name: '${name}',
  image: String(valuesRef('image.repository')) + ':' + String(valuesRef('image.tag')),
  replicas: Number(valuesRef('replicas') as unknown as string) as any,
  containerPort: 80,
  env: {
    APP_NAME: '${name}',
    RELEASE: helm.releaseName,
  },
});

rutter.addService({
  name: '${name}',
  ports: [{ port: Number(valuesRef('service.port') as unknown as string) as any, targetPort: 80 }],
  type: 'ClusterIP',
  selector: { app: '${name}' },
});

// Optional ingress with advanced path routing and TLS support
// Helm conditionals can be embedded as comments; template users can wrap templates with if blocks
// Here we just generate an ingress; for real conditional generation you could split assets yourself.
rutter.addIngress({
  name: '${name}',
  ingressClassName: String(valuesRef('ingress.className')),
  rules: [{
    host: String(valuesRef('ingress.host')),
    paths: [{
      path: '/',
      pathType: 'Prefix',
      backend: {
        service: {
          name: '${name}',
          port: { number: Number(valuesRef('service.port') as unknown as string) as any },
        },
      },
    }],
  }],
});

export default function run(outDir: string) {
  rutter.write(outDir);
}
`;
}

interface CliFlags {
  dryRun: boolean;
  silent: boolean;
  env?: string;
  versionBump?: string;
  set: Record&lt;string, string&gt;;
}

// eslint-disable-next-line sonarjs/cognitive-complexity -- CLI argument parsing requires multiple conditions
function parseArgs(): { cmd: string; args: string[]; flags: CliFlags } {
  /* eslint-disable security/detect-object-injection */
  const argv = process.argv.slice(2);
  const flags: CliFlags = { dryRun: false, silent: false, set: {} };
  const args: string[] = [];
  let cmd = '';

  for (let i = 0; i &lt; argv.length; i++) {
    const arg = argv[i];

    if (arg === '--dry-run') {
      flags.dryRun = true;
    } else if (arg === '--silent') {
      flags.silent = true;
    } else if (arg === '--env' &amp;&amp; i + 1 &lt; argv.length) {
      const nextArg = argv[++i];
      if (nextArg) flags.env = nextArg;
    } else if (arg === '--version-bump' &amp;&amp; i + 1 &lt; argv.length) {
      const nextArg = argv[++i];
      if (nextArg) flags.versionBump = nextArg;
    } else if (arg === '--set' &amp;&amp; i + 1 &lt; argv.length) {
      const setValue = argv[++i];
      if (setValue) {
        const [key, value] = setValue.split('=', 2);
        if (key &amp;&amp; value !== undefined) {
          flags.set[key] = value;
        }
      }
    } else if (arg === '--version' || arg === '-v') {
      showVersion();
      process.exit(0);
    } else if (arg &amp;&amp; !arg.startsWith('--')) {
      if (!cmd) {
        cmd = arg;
      } else {
        args.push(arg);
      }
    }
  }
  /* eslint-enable security/detect-object-injection */

  return { cmd, args, flags };
}

function showVersion() {
  const packagePath = path.join(__dirname, '..', 'package.json');
  try {
    const packageJson = JSON.parse(fs.readFileSync(packagePath, 'utf8'));
    console.log(`timonel v${packageJson.version}`);
  } catch {
    console.log('timonel (version unknown)');
  }
}

function log(message: string, silent = false) {
  if (!silent) {
    console.log(message);
  }
}

async function main() {
  const { cmd, args, flags } = parseArgs();

  switch (cmd) {
    case 'init':
      await cmdInit(args[0], flags.silent);
      break;
    case 'validate':
      await cmdValidate(args[0], flags.silent);
      break;
    case 'synth':
      await cmdSynth(args[0], args[1], flags);
      break;
    case 'diff':
      await cmdDiff(args[0], args[1], flags.silent);
      break;
    case 'deploy':
      await cmdDeploy(args[0], args[1], flags);
      break;
    case 'package':
      await cmdPackage(args[0], args[1], flags.silent);
      break;
    case 'umbrella':
      await cmdUmbrella(args[0], args.slice(1), flags);
      break;
    case 'version':
    case '-v':
    case '--version':
      showVersion();
      break;
    case '-h':
    case '--help':
    default:
      usageAndExit();
  }
}

main().catch((err) =&gt; {
  console.error(err);
  process.exit(1);
});</content>
    

  </file>
  <file>
    
  
    <path>src/index.ts</path>
    
  
    <content>export * from './lib/Rutter.js';
export * from './lib/HelmChartWriter.js';
export * from './lib/helm.js';
export * from './lib/umbrella.js';</content>
    

  </file>
</repository_files>
<statistics>
  <total_files>67</total_files>
  <total_chars>415268</total_chars>
  <total_tokens>0</total_tokens>
  <generated_at>2025-09-07 02:31:00</generated_at>
</statistics>
</repository>